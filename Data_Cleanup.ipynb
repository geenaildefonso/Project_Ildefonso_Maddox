{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In beginning to clean up the code, as mentioned Mary Lauren began to clean up the code initially by creating a data path to the data, and following by reading in each of the data sets given the data path and file name. From there, "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "###\n",
    "#   Mary Lauren Benton, 2017\n",
    "###\n",
    "\n",
    "###\n",
    "#   imports & variables\n",
    "###\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy  as np\n",
    "import csv\n",
    "data_path = \"/Users/sarahmaddox/Desktop/Data/\" ##THIS NEEDS TO BE CHANGED BASED ON WHERE THE DATA IS\n",
    "\n",
    "\n",
    "###\n",
    "#   ADT\n",
    "### \n",
    "adt = pd.read_csv(data_path+\"FONNESBECK_ADT.csv\", na_values=[''],\n",
    "                  parse_dates=['Admission_date', 'Event_Date', 'DISCHARGE_DATE'],\n",
    "                  encoding = \"ISO-8859-1\")\n",
    "adt.head()\n",
    "\n",
    "# rename the columns and replace event strings with simpler versions\n",
    "# #todo -- expand categorical variables using get_dummies\n",
    "adt_clean = (adt\n",
    "             .rename(columns={\"RUID\": \"patient_id\", \n",
    "                              \"Event\":\"adt_event\", \n",
    "                              \"Admission_date\": \"admission_date\",\n",
    "                              \"Event_Date\": \"adt_event_date\", \n",
    "                              \"SRV_CODE\": \"srv_code\",\n",
    "                              \"CHIEF_COMPLAINT\": \"chief_complaint\", \n",
    "                              \"DISCHARGE_DATE\": \"discharge_date\"})\n",
    "             .replace({'adt_event': {'.*Admit': 'admit',\n",
    "                                     '.*Discharge': 'discharge', \n",
    "                                     '.*Transfer': 'transfer'}}, regex=True))\n",
    "\n",
    "adt_clean.head()\n",
    "\n",
    "# calculate the amount of missing data in the ADT table\n",
    "adt_clean.isnull().sum()\n",
    "\n",
    "# presumably only discharges will have discharge dates; these actual missing data\n",
    "# #todo -- decide how to handle missing dates\n",
    "df = (adt_clean[adt_clean.adt_event == 'discharge']).isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "patient_id           0\n",
       "adt_event            0\n",
       "admission_date       2\n",
       "adt_event_date       0\n",
       "srv_code             0\n",
       "chief_complaint    265\n",
       "discharge_date       0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "unconverted data remains: 07",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-9e1300bf36c1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madmission_date\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0md\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mdatetime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstrptime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0md\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'%m/%d/%y'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/anaconda3/envs/bios8366/lib/python3.6/site-packages/pandas/core/series.py\u001b[0m in \u001b[0;36mapply\u001b[0;34m(self, func, convert_dtype, args, **kwds)\u001b[0m\n\u001b[1;32m   2508\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2509\u001b[0m                 \u001b[0mvalues\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masobject\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2510\u001b[0;31m                 \u001b[0mmapped\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap_infer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconvert\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconvert_dtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2511\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2512\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmapped\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmapped\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mSeries\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/src/inference.pyx\u001b[0m in \u001b[0;36mpandas._libs.lib.map_infer\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m<ipython-input-11-9e1300bf36c1>\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(d)\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madmission_date\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0md\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mdatetime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstrptime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0md\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'%m/%d/%y'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/anaconda3/envs/bios8366/lib/python3.6/_strptime.py\u001b[0m in \u001b[0;36m_strptime_datetime\u001b[0;34m(cls, data_string, format)\u001b[0m\n\u001b[1;32m    563\u001b[0m     \"\"\"Return a class cls instance based on the input string and the\n\u001b[1;32m    564\u001b[0m     format string.\"\"\"\n\u001b[0;32m--> 565\u001b[0;31m     \u001b[0mtt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfraction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_strptime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_string\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mformat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    566\u001b[0m     \u001b[0mtzname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgmtoff\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtt\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    567\u001b[0m     \u001b[0margs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtt\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m6\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mfraction\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/envs/bios8366/lib/python3.6/_strptime.py\u001b[0m in \u001b[0;36m_strptime\u001b[0;34m(data_string, format)\u001b[0m\n\u001b[1;32m    363\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_string\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mfound\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    364\u001b[0m         raise ValueError(\"unconverted data remains: %s\" %\n\u001b[0;32m--> 365\u001b[0;31m                           data_string[found.end():])\n\u001b[0m\u001b[1;32m    366\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    367\u001b[0m     \u001b[0miso_year\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0myear\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: unconverted data remains: 07"
     ]
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "from datetime import date, time \n",
    "df = pd.DataFrame(adt_clean, columns = ['patient_id','adt_event','admission_date', 'discharge_date'])\n",
    "x = df[df.adt_event != 'transfer']\n",
    "x = x[x.adt_event != 'discharge']\n",
    "# adt_final\n",
    "x = x[['patient_id','admission_date', 'discharge_date']]\n",
    "x.head()\n",
    "\n",
    "x.admission_date.apply(lambda d: datetime.strptime(d, '%m/%d/%y'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "patient_id      0\n",
       "bmi           307\n",
       "bmi_date        9\n",
       "weight        307\n",
       "height          0\n",
       "pregnant        0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "###\n",
    "#   BMI\n",
    "###\n",
    "bmi = pd.read_csv(data_path+\"FONNESBECK_BMI.csv\", parse_dates=['Date_BMI'], infer_datetime_format=True)\n",
    "bmi.head()\n",
    "\n",
    "bmi_clean = (bmi\n",
    "             .rename(columns={\"RUID\": \"patient_id\", \n",
    "                              \"BMI\": \"bmi\",\n",
    "                              \"Date_BMI\": \"bmi_date\", \n",
    "                              \"BMI_Weight\": \"weight\",\n",
    "                              \"BMI_Height\": \"height\", \n",
    "                              \"Pregnancy_Indicator\": \"pregnant\"}))\n",
    "bmi_clean['bmi_date'] = pd.to_datetime(bmi_clean.bmi_date, errors='coerce')\n",
    "bmi_clean.head()\n",
    "\n",
    "# small amount of missingness\n",
    "# #todo -- possible to fill in missing if same patient\n",
    "bmi_clean.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "patient_id     0\n",
       "systolic       0\n",
       "diastolic      0\n",
       "bp_date       26\n",
       "dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "###\n",
    "#   BP\n",
    "###\n",
    "bp = pd.read_csv(data_path+\"FONNESBECK_BP.csv\", parse_dates=['Measure_date'], infer_datetime_format=True)\n",
    "bp.head()\n",
    "\n",
    "bp_clean = (bp\n",
    "            .rename(columns={\"RUID\": \"patient_id\", \n",
    "                             \"SYSTOLIC\": \"systolic\",\n",
    "                             \"DIASTOLIC\": \"diastolic\", \n",
    "                             \"Measure_date\": \"bp_date\"}))\n",
    "bp_clean['bp_date'] = pd.to_datetime(bp_clean.bp_date, errors='coerce')\n",
    "bp_clean.head()\n",
    "\n",
    "# only missing dates, may not need to address\n",
    "bp_clean.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "patient_id        0\n",
       "cpt_code          0\n",
       "cpt_event_date    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "###\n",
    "#   CPT\n",
    "###\n",
    "cpt = pd.read_csv(data_path+\"FONNESBECK_CPT.csv\", parse_dates=['Event_date'], infer_datetime_format=True)\n",
    "cpt.head()\n",
    "\n",
    "cpt_clean = (cpt\n",
    "             .rename(columns={\"RUID\": \"patient_id\", \n",
    "                              \"CPT_Code\": \"cpt_code\",\n",
    "                              \"Event_date\": \"cpt_event_date\"}))\n",
    "cpt_clean.head()\n",
    "\n",
    "# no missing data\n",
    "cpt_clean.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "patient_id    0\n",
       "egfr          0\n",
       "egfr_date     0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "###\n",
    "#   EGFR\n",
    "###\n",
    "egfr = pd.read_csv(data_path+\"FONNESBECK_EGFR.csv\", parse_dates=['egfr_date'], infer_datetime_format=True)\n",
    "egfr.head()\n",
    "\n",
    "egfr_clean = (egfr\n",
    "              .rename(columns={\"RUID\": \"patient_id\", \n",
    "                               \"EGFR\": \"egfr\"}))\n",
    "egfr_clean.head()\n",
    "\n",
    "# no missing data\n",
    "egfr_clean.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "patient_id         0\n",
       "icd9_code          1\n",
       "icd9_event_date    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "###\n",
    "#   ICD9\n",
    "###\n",
    "icd9 = pd.read_csv(data_path+\"FONNESBECK_ICD9.csv\", parse_dates=['Event_date'], infer_datetime_format=True)\n",
    "icd9.head()\n",
    "\n",
    "icd9_clean = (icd9\n",
    "              .rename(columns={\"RUID\": \"patient_id\", \n",
    "                               \"ICD9_Code\": \"icd9_code\",\n",
    "                               \"Event_date\": \"icd9_event_date\"}))\n",
    "icd9_clean.head()\n",
    "\n",
    "# no missing data\n",
    "icd9_clean.isnull().sum()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "patient_id            0\n",
       "short_lab_name        4\n",
       "lab_date              0\n",
       "lab_value         18489\n",
       "dtype: int64"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "###\n",
    "#   LAB\n",
    "###\n",
    "lab = pd.read_csv(data_path+\"FONNESBECK_LAB.csv\", parse_dates=['Lab_date'], \n",
    "                  infer_datetime_format=True, quoting=csv.QUOTE_NONE, na_values=['>'])\n",
    "lab.head()\n",
    "\n",
    "lab_clean = (lab\n",
    "             .rename(columns={\"RUID\": \"patient_id\", \n",
    "                              \"Lab_name\": \"short_lab_name\",\n",
    "                              \"Lab_date\": \"lab_date\", \n",
    "                              \"Lab_value\": \"lab_value\"}))\n",
    "lab_clean.head()\n",
    "\n",
    "# decent number of missing lab values\n",
    "# may be able to impute missing values if same patient \n",
    "lab_clean.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "patient_id                0\n",
       "drug_entry_date        1110\n",
       "drug_name               201\n",
       "drug_form          10178627\n",
       "drug_strength       4950659\n",
       "drug_route          4431974\n",
       "drug_dose           8842506\n",
       "drug_freq           4702238\n",
       "drug_duration      12626046\n",
       "dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "###\n",
    "#   MED\n",
    "###\n",
    "med = pd.read_csv(data_path+\"FONNESBECK_MED.csv\", parse_dates=['Entry_Date'], infer_datetime_format=True)\n",
    "med.head()\n",
    "\n",
    "med_clean = (med\n",
    "             .rename(columns={\"RUID\": \"patient_id\", \n",
    "                              \"Entry_Date\": \"drug_entry_date\",\n",
    "                              \"Drug_Name\": \"drug_name\", \n",
    "                              \"DRUG_FORM\": \"drug_form\",\n",
    "                              \"DRUG_STRENGTH\": \"drug_strength\",\n",
    "                              \"Route\": \"drug_route\",\n",
    "                              \"Dose_Amt\": \"drug_dose\",\n",
    "                              \"Drug_Freq\": \"drug_freq\",\n",
    "                              \"Duration\": \"drug_duration\"}))\n",
    "med_clean.head()\n",
    "\n",
    "# lots of missing data in this table\n",
    "# many cols likely uninformative; drug_name might be most useful\n",
    "med_clean.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "patient_id       0\n",
       "sex             43\n",
       "DOB             43\n",
       "DOD           6642\n",
       "race             0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "###\n",
    "#   PHENOTYPE\n",
    "###\n",
    "phenotype = pd.read_csv(data_path+\"FONNESBECK_phenotype.csv\", parse_dates=['DOB', 'DOD'], infer_datetime_format=True)\n",
    "phenotype.head()\n",
    "\n",
    "phenotype_clean = (phenotype\n",
    "                   .rename(columns={\"RUID\": \"patient_id\", \n",
    "                                    \"Sex\": \"sex\",\n",
    "                                    \"DOB\": \"DOB\", \n",
    "                                    \"DOD\": \"DOD\",\n",
    "                                    \"Race\": \"race\"})\n",
    "                   .replace({'sex':  {'F': 0,'M': 1, 'U': 'NaN', '.': 'NaN', 'NA': 'NaN'}}))\n",
    "phenotype_clean.head()\n",
    "\n",
    "# lots of missing DOBs and sex\n",
    "# living patients will have missing DOD\n",
    "# #todo -- decide whether to collapse race into fewer categories\n",
    "phenotype_clean.isnull().sum()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
