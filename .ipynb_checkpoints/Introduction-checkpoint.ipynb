{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overview of Problem"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have received Vanderbilt hospital data extracted from the Synthetic Derivative. At Vanderbilt, bioinformaticians helped to create a \"mirror image\" of electronic medical records such as those in BioVU, Vanderbilt's biorepository of DNA extracted from discarded blood collected during routine clinical testing. This mirror of the EMR is called the Synthetic Derivative, and it contains over 2 million individual patients with all clinical information available for the past 10 years. It has been scrubbed of HIPAA identifiers with an eror rate of ~0.01%, meaning that the data has been deidentified with a subject ID. \n",
    "\n",
    "The objective of this project is to employ modeling tools introduced in class to fit prediction models for patient readmission within 30 days of discharge using given data. The data includes multiple variables, detailed below in \"Data.\" Ideally, our model will be able to well predict readmission within 30 days of discharge for a patient using the admit/discharge/transfer events data. The rest of the data detials information about the patients themselves, tests and treatments they underwent at Vanderbilt, and lab results and medication. Using these variables, we hope to accurately predict readmission. This information could be very useful for actually clinicians hoping to predict which patients may need to be readmitted, and which characteristics/tests cause them to be readmitted. Once this is determined, that subset of patients could be given more attention and/or tests to prevent readmission."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Goal and Structure of Project"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This project will introduce several approaches to predictive modeling of patient readmission within 30 days of discharge. Three approaches are detailed in the following jupyter notebooks, each of which may include more than one modeling type, attempts to improve each model and test performance, and tuning of the models to increase the goodness of fit. Cross-validation will be used when appropriate, and model selection methods and/or explanations of the models chosen will be provided for each notebook. We will then justify and describe each model selection, and provide visualizations and discussions of the results. The models will be compared using goodness of fit tests and other performance characteristics. For clarification, the steps for each model notebook are listed below, and enumerated in the following 3 modeling notebooks. \n",
    "\n",
    "1. Identify the model approach(es), describe, and justify the selection\n",
    "2. Code, parameterize, and run model (including visualization)\n",
    "3. Cross-validation\n",
    "4. Goodness of fit assessments, performance characteristics (including visualization)\n",
    "5. Improvements to model/tuning of parameters; model selection methods, justification of improvements/tests\n",
    "6. Comparison of models; identification of best model\n",
    "7. Results \n",
    "8. Implications of model and conclusions\n",
    "\n",
    "We have also included a conclusions notebook that details the comparisons of the 3 model types, which ones worked and didn't work, our best model, and future directions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data and cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ADT: Admit/Discharge/Transfer Events. Includes the variables:\n",
    "1. \"Event\" (Admit, Transfer, or Discharge)\n",
    "2. \"Admission_date\" (date format, M/DD/YY)\n",
    "3. \"Event_Date\" (date)\n",
    "4. \"SRV_CODE\" (e.g. ORT, NEU, GMB)\n",
    "5. \"CHIEF_COMPLAINT\" (e.g. CP, CHEST PAIN, SEIZURES)\n",
    "6. \"DISCHARGE_DATE\" (date)\n",
    "\n",
    "This dataframe was cleaned by: **GEEEEEEEEENA**\n",
    "\n",
    "This data frame was used to organize the variables for each patient for each hospital stay, as well as to generate a variable for prediction. This \"y\" variable dataframe was generated by looking at one patient and their admission and discharge dates. If the patient had any admission dates within 30 days of a discharge date, this variable is given the value \"1\"; if there were none, the patient got a value of \"0.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#   imports & variables\n",
    "###\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy  as np\n",
    "import csv\n",
    "\n",
    "data_path = \"/Users/geenaildefonso/Downloads/PData/\"\n",
    "\n",
    "\n",
    "###\n",
    "#   ADT\n",
    "### \n",
    "adt = pd.read_csv(data_path+\"FONNESBECK_ADT.csv\", na_values=[''], \n",
    "                  parse_dates=['Admission_date', 'Event_Date', 'DISCHARGE_DATE'],\n",
    "                  encoding = \"ISO-8859-1\")\n",
    "adt.head()\n",
    "\n",
    "# rename the columns and replace event strings with simpler versions\n",
    "# #todo -- expand categorical variables using get_dummies\n",
    "adt_clean = (adt\n",
    "             .rename(columns={\"RUID\": \"patient_id\", \n",
    "                              \"Event\":\"adt_event\", \n",
    "                              \"Admission_date\": \"admission_date\",\n",
    "                              \"Event_Date\": \"adt_event_date\", \n",
    "                              \"SRV_CODE\": \"srv_code\",\n",
    "                              \"CHIEF_COMPLAINT\": \"chief_complaint\", \n",
    "                              \"DISCHARGE_DATE\": \"discharge_date\"})\n",
    "             .replace({'adt_event': {'.*Admit': 'admit',\n",
    "                                     '.*Discharge': 'discharge', \n",
    "                                     '.*Transfer': 'transfer'}}, regex=True))\n",
    "\n",
    "adt_clean.head()\n",
    "\n",
    "# calculate the amount of missing data in the ADT table\n",
    "adt_clean.isnull().sum()\n",
    "\n",
    "# presumably only discharges will have discharge dates; these actual missing data\n",
    "# #todo -- decide how to handle missing dates\n",
    "(adt_clean[adt_clean.adt_event == 'discharge']).isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(adt_clean, columns = ['patient_id','adt_event','admission_date', 'discharge_date'])\n",
    "df = df[df.adt_event != 'transfer']\n",
    "df = df[df.adt_event != 'discharge']\n",
    "# adt_final\n",
    "df_adt = df[['patient_id','admission_date', 'discharge_date']]\n",
    "df_adt = df_adt.sort_values('admission_date')\n",
    "df_adt = df_adt.sort_values('patient_id')\n",
    "df_adt.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "BMI: Body mass index measurement information.\n",
    "Includes the variables:\n",
    "1. \"BMI\" (numeric)\n",
    "2. Date_BMI (date M/DD/YY)\n",
    "3. BMI_Weight (numeric, in kg)\n",
    "4. BMI_Height (numeric, in cm)\n",
    "5. Pregnancy_Indicator (0, 1).\n",
    "\n",
    "Cleaning of the BMI dataset: We decided that BMI gave us enough information, and height and weight were a little superfluous. In order to reduce the number of possible variables in the model, we only included BMI, the date the BMI measurement was taken, and a pregnancy indicator in the final dataset for modeling. We used \"Date_BMI\" to include this data into our larger \"X\" dataset by checking where this date fell between the patient's admission and discharge dates and adding the data to that row."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###\n",
    "#   BMI\n",
    "###\n",
    "bmi = pd.read_csv(data_path+\"FONNESBECK_BMI.csv\", parse_dates=['Date_BMI'], infer_datetime_format=True)\n",
    "bmi.head()\n",
    "\n",
    "bmi_clean = (bmi\n",
    "             .rename(columns={\"RUID\": \"patient_id\", \n",
    "                              \"BMI\": \"bmi\",\n",
    "                              \"Date_BMI\": \"bmi_date\", \n",
    "                              \"BMI_Weight\": \"weight\",\n",
    "                              \"BMI_Height\": \"height\", \n",
    "                              \"Pregnancy_Indicator\": \"pregnant\"}))\n",
    "bmi_clean['bmi_date'] = pd.to_datetime(bmi_clean.bmi_date, errors='coerce')\n",
    "bmi_clean.head()\n",
    "\n",
    "# small amount of missingness\n",
    "# #todo -- possible to fill in missing if same patient\n",
    "# bmi_clean.isnull().sum()\n",
    "df_bmi = bmi_clean.drop_duplicates(subset='bmi_date')\n",
    "df_bmi = df_bmi[['patient_id', 'bmi', 'bmi_date']]\n",
    "df_bmi.head()\n",
    "bmi_clean.groupby('bmi_date',sort=True).sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "BP: Blood pressure measurements. Includes the variables:\n",
    "1. \"SYSTOLIC\" (integer)\n",
    "2. \"DIASTOLIC\" (integer)\n",
    "3. \"Measure_date\" (M/DD/YY)\n",
    "\n",
    "The measure date was used to include both the Systolic and Diastolic variables into the larger \"X\" dataset using the same method as the BMI data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###\n",
    "#   BP\n",
    "###\n",
    "bp = pd.read_csv(data_path+\"FONNESBECK_BP.csv\", parse_dates=['Measure_date'], infer_datetime_format=True)\n",
    "bp.head()\n",
    "\n",
    "bp_clean = (bp\n",
    "            .rename(columns={\"RUID\": \"patient_id\", \n",
    "                             \"SYSTOLIC\": \"systolic\",\n",
    "                             \"DIASTOLIC\": \"diastolic\", \n",
    "                             \"Measure_date\": \"bp_date\"}))\n",
    "bp_clean['bp_date'] = pd.to_datetime(bp_clean.bp_date, errors='coerce')\n",
    "bp_clean.head()\n",
    "\n",
    "# only missing dates, may not need to address\n",
    "bp_clean.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MED: Medications information, including dose and duration.\n",
    "Includes the variables:\n",
    "1. \"Entry_Date\" (date M/DD/YY)\t\n",
    "2. \"Drug_Name\" (common drug name, string)\t\n",
    "3. \"DRUG_FORM\" (if drug comes in multiple forms, this describes which form is given. E.g. nebulizer versus inhaler for albuterol)\t\n",
    "4. \"DRUG_STRENGTH\" (mL, or NA)\n",
    "5. \"Route\" (Route of drug administration; e.g. IV, FLUSH, PO)\n",
    "6. \"Dose_Amt\" (Amount of drug, variable units; g, ML/HR, units)\n",
    "7. \"Drug_Freq\" (number of times given/how the drug is given; e.g. twice daily, once, Q1H PRN)\n",
    "8. \"Duration\" (length of time drug is given; e.g. months, days, etc)\n",
    "\n",
    "Cleaning of the MED dataset: From this dataset, we used Entry_date to include the data in our larger \"X\" data set. We included Drug_Name and dose amount, combined to be one variable. No other information from this dataset was used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###\n",
    "#   MED\n",
    "###\n",
    "med = pd.read_csv(data_path+\"FONNESBECK_MED.csv\", parse_dates=['Entry_Date'], infer_datetime_format=True)\n",
    "med.head()\n",
    "\n",
    "med_clean = (med\n",
    "             .rename(columns={\"RUID\": \"patient_id\", \n",
    "                              \"Entry_Date\": \"drug_entry_date\",\n",
    "                              \"Drug_Name\": \"drug_name\", \n",
    "                              \"DRUG_FORM\": \"drug_form\",\n",
    "                              \"DRUG_STRENGTH\": \"drug_strength\",\n",
    "                              \"Route\": \"drug_route\",\n",
    "                              \"Dose_Amt\": \"drug_dose\",\n",
    "                              \"Drug_Freq\": \"drug_freq\",\n",
    "                              \"Duration\": \"drug_duration\"}))\n",
    "med_clean.head()\n",
    "\n",
    "# lots of missing data in this table\n",
    "# many cols likely uninformative; drug_name might be most useful\n",
    "med_clean.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CPT: Procedure codes. Variables include:\n",
    "1. \"CPT_code\" (integer in most cases to describe categorical data)\n",
    "2. \"Event_date\" (M/DD/YY)\n",
    "\n",
    "This data was included in models that could predict using categorical data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "EGFR: Estimated Glomerular Filtration Rate measurements, used to screen for kidney damage. Obtained from a creatine lab. Includes the variables:\n",
    "1. \"EGFR\" (continuous data)\n",
    "2. \"egfr_date\" (date M/DD/YY)\n",
    "\n",
    "Again, we included this in the X dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###\n",
    "#   CPT\n",
    "###\n",
    "cpt = pd.read_csv(data_path+\"FONNESBECK_CPT.csv\", parse_dates=['Event_date'], infer_datetime_format=True)\n",
    "cpt.head()\n",
    "\n",
    "cpt_clean = (cpt\n",
    "             .rename(columns={\"RUID\": \"patient_id\", \n",
    "                              \"CPT_Code\": \"cpt_code\",\n",
    "                              \"Event_date\": \"cpt_event_date\"}))\n",
    "cpt_clean.head()\n",
    "\n",
    "# no missing data\n",
    "cpt_clean.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ICD9: Coding of diagnosed diseases and health problems. This is an international standard for classifying diseases, including nuanced classifications of a wide variety of signs, symptoms, abnormal findings, complaints, social circumstances, and external causes of injury or disease. \n",
    "\n",
    "1. \"ICD9_Code\" (code for each disease/health problem)\n",
    "2. \"Event_date\"\n",
    "\n",
    "This data is included as categorical data in our models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###\n",
    "#   ICD9\n",
    "###\n",
    "icd9 = pd.read_csv(data_path+\"FONNESBECK_ICD9.csv\", parse_dates=['Event_date'], infer_datetime_format=True)\n",
    "icd9.head()\n",
    "\n",
    "icd9_clean = (icd9\n",
    "              .rename(columns={\"RUID\": \"patient_id\", \n",
    "                               \"ICD9_Code\": \"icd9_code\",\n",
    "                               \"Event_date\": \"icd9_event_date\"}))\n",
    "icd9_clean.head()\n",
    "\n",
    "# no missing data\n",
    "icd9_clean.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LAB: lab results, including the variables:\n",
    "1. \"Lab_name\" (Abbreviated name of lab test)\n",
    "2. \"Lab_date\" (date)\n",
    "3. \"Lab_value\" (result of test; may be numerical or categorical, such as blood type)\n",
    "\n",
    "This data was incorporated into our large dataset as categorical data. This information is hard (and somewhat unneccessary) to add to our models; for example, we do not expect blood type to have an effect on rate of readmission. For this reason, the data was not investigated as much as the other datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###\n",
    "#   LAB\n",
    "###\n",
    "lab = pd.read_csv(data_path+\"FONNESBECK_LAB.csv\", parse_dates=['Lab_date'], \n",
    "                  infer_datetime_format=True, quoting=csv.QUOTE_NONE, na_values=['>'])\n",
    "lab.head()\n",
    "\n",
    "lab_clean = (lab\n",
    "             .rename(columns={\"RUID\": \"patient_id\", \n",
    "                              \"Lab_name\": \"short_lab_name\",\n",
    "                              \"Lab_date\": \"lab_date\", \n",
    "                              \"Lab_value\": \"lab_value\"}))\n",
    "lab_clean.head()\n",
    "\n",
    "# decent number of missing lab values\n",
    "# may be able to impute missing values if same patient \n",
    "lab_clean.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Phenotype: Patient attributes, including sex, race, and dates of birth and death.\n",
    "Includes the variables: \n",
    "1. \"Sex\" (F or M) \n",
    "2. \"DOB\" (date of birth)\n",
    "3. \"DOD\" (date of death)\n",
    "4. \"Race\" (W = white, B = black, A = Asian, N = Native American, H = hispanic, U = unidentified). \n",
    "\n",
    "Cleaning of the Phenotype dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "###\n",
    "#   PHENOTYPE\n",
    "###\n",
    "phenotype = pd.read_csv(data_path+\"FONNESBECK_phenotype.csv\", parse_dates=['DOB', 'DOD'], infer_datetime_format=True)\n",
    "phenotype.head()\n",
    "\n",
    "phenotype_clean = (phenotype\n",
    "                   .rename(columns={\"RUID\": \"patient_id\", \n",
    "                                    \"Sex\": \"sex\",\n",
    "                                    \"DOB\": \"DOB\", \n",
    "                                    \"DOD\": \"DOD\",\n",
    "                                    \"Race\": \"race\"})\n",
    "                   .replace({'sex':  {'F': 0,'M': 1, 'U': 'NaN', '.': 'NaN', 'NA': 'NaN'}}))\n",
    "phenotype_clean.head()\n",
    "\n",
    "# lots of missing DOBs and sex\n",
    "# living patients will have missing DOD\n",
    "# #todo -- decide whether to collapse race into fewer categories\n",
    "phenotype_clean.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating the X dataset for prediction: Variables of Interest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After all of the above is done, we have each cleaned and organized dataset, and the ADT data is arranged into a dataframe with patient ID, admission date, and discharge date. Thus, each patient ID may be repeated for multiple rows, depending on how often they were admitted, but each visit should only be recorded once in its own row. To make a large dataset with all of the information we want to include for modeling, we will add data from the other datasets using the dates in those data sets. We will parse the other data sets (for example, BMI), by date (Date_BMI). For each event in the BMI dataset, we will find the matching patient by ID. We will then find the correct column by comparing the date of the measurement (Date_BMI) to the Admission date and Discharge date in each row for that patient (i.e., adding the BMI measurement to the column where the patient ID matches and Admission_date $\\leq$ Date_BMI $\\leq$ Discharge_date.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating the Y variable dataset for prediction: Rate of Readmission"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We used the same cleaned and organized ABT dataset to create a \"Y\" dataset that will be used to check our predictions of readmissions within 30 days of discharge. For each patient, we ran a for loop through the rows. Each row has a different discharge date, and this date was compared to all of the other admission dates to see if any admission dates were within 30 days of the discharge. If there is such a date, the loop is broken, the patient received a \"1\" value for a \"readmitted\" variable, and the next patient is investigated. This will give us a binary variable corresponding to the patients that were readmitted within 30 days at least once at any time. When building our models, we can use this information to check the accuracy of our models and for cross-validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "###\n",
    "#   Mary Lauren Benton, 2017\n",
    "###\n",
    "\n",
    "###\n",
    "#   imports & variables\n",
    "###\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy  as np\n",
    "import csv\n",
    "data_path = \"/Users/sarahmaddox/Desktop/Data/\" ##THIS NEEDS TO BE CHANGED BASED ON WHERE THE DATA IS\n",
    "\n",
    "\n",
    "###\n",
    "#   ADT\n",
    "### \n",
    "adt = pd.read_csv(data_path+\"FONNESBECK_ADT.csv\", na_values=[''],\n",
    "                  parse_dates=['Admission_date', 'Event_Date', 'DISCHARGE_DATE'],\n",
    "                  encoding = \"ISO-8859-1\")\n",
    "adt.head()\n",
    "\n",
    "# rename the columns and replace event strings with simpler versions\n",
    "# #todo -- expand categorical variables using get_dummies\n",
    "adt_clean = (adt\n",
    "             .rename(columns={\"RUID\": \"patient_id\", \n",
    "                              \"Event\":\"adt_event\", \n",
    "                              \"Admission_date\": \"admission_date\",\n",
    "                              \"Event_Date\": \"adt_event_date\", \n",
    "                              \"SRV_CODE\": \"srv_code\",\n",
    "                              \"CHIEF_COMPLAINT\": \"chief_complaint\", \n",
    "                              \"DISCHARGE_DATE\": \"discharge_date\"})\n",
    "             .replace({'adt_event': {'.*Admit': 'admit',\n",
    "                                     '.*Discharge': 'discharge', \n",
    "                                     '.*Transfer': 'transfer'}}, regex=True))\n",
    "\n",
    "adt_clean.head()\n",
    "\n",
    "# calculate the amount of missing data in the ADT table\n",
    "adt_clean.isnull().sum()\n",
    "\n",
    "# presumably only discharges will have discharge dates; these actual missing data\n",
    "# #todo -- decide how to handle missing dates\n",
    "df = (adt_clean[adt_clean.adt_event == 'discharge']).isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "patient_id           0\n",
       "adt_event            0\n",
       "admission_date       2\n",
       "adt_event_date       0\n",
       "srv_code             0\n",
       "chief_complaint    265\n",
       "discharge_date       0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>patient_id</th>\n",
       "      <th>admission_date</th>\n",
       "      <th>discharge_date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>50135262</td>\n",
       "      <td>2007-02-08</td>\n",
       "      <td>2007-02-12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>50135262</td>\n",
       "      <td>2011-02-11</td>\n",
       "      <td>2011-02-23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>50135262</td>\n",
       "      <td>2008-02-24</td>\n",
       "      <td>2008-02-28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>50135262</td>\n",
       "      <td>2008-04-12</td>\n",
       "      <td>2008-04-13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>50135262</td>\n",
       "      <td>2012-05-23</td>\n",
       "      <td>2012-05-27</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   patient_id admission_date discharge_date\n",
       "0    50135262     2007-02-08     2007-02-12\n",
       "1    50135262     2011-02-11     2011-02-23\n",
       "2    50135262     2008-02-24     2008-02-28\n",
       "3    50135262     2008-04-12     2008-04-13\n",
       "4    50135262     2012-05-23     2012-05-27"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "from datetime import date, time \n",
    "df = pd.DataFrame(adt_clean, columns = ['patient_id','adt_event','admission_date', 'discharge_date'])\n",
    "x = df[df.adt_event != 'transfer']\n",
    "x = x[x.adt_event != 'discharge']\n",
    "# adt_final\n",
    "x = x[['patient_id','admission_date', 'discharge_date']]\n",
    "x=x.reset_index(drop=True)\n",
    "x.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the above dataframe, I can compare discharge dates and admission dates for each patient. I will write a loop below that looks patient by patient. For each patient, I will loop through the discharge dates and compare them to the admission dates. If any are within 30 days of discharge, I will break from the inner loop, give the patient a \"1\", and move to the next patient."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([50135262, 50135361, 50135369, ..., 53736421, 53736422, 53736423])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unique_ids = x.patient_id.unique()\n",
    "unique_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7914\n"
     ]
    }
   ],
   "source": [
    "patients_readmitted = np.zeros(len(unique_ids))\n",
    "print(len(unique_ids))\n",
    "for p, count in zip(unique_ids, range(len(unique_ids))):\n",
    "#for p in [50135262]:\n",
    "#make a subsetted dataframe of just that ID\n",
    "    p_df = x[x.patient_id == p]\n",
    "    p_df=p_df.reset_index(drop=True)\n",
    "    #for each discharge_date in that list:\n",
    "    for i in range(len(p_df)):\n",
    "    #compare the discharge date to all of the admission dates in list\n",
    "        discharge = p_df.loc[i][\"discharge_date\"]\n",
    "        for j in range(len(p_df)):\n",
    "            readmit = p_df.loc[j][\"admission_date\"]\n",
    "            if (readmit - discharge > pd.to_timedelta('0 days')) and (readmit - discharge < pd.to_timedelta('30 days')):\n",
    "                patients_readmitted[count]=patients_readmitted[count]+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = pd.DataFrame({'patient_id':unique_ids, 'readmission':patients_readmitted})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>patient_id</th>\n",
       "      <th>readmission</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>50135262</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>50135361</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>50135369</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>50135375</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>50135425</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>50135437</td>\n",
       "      <td>41.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>50135624</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>50135735</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>50135759</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>50135821</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>50135887</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>50135891</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>50135968</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>50136007</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>50136045</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>50136072</td>\n",
       "      <td>9.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>50136118</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>50136183</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>50136213</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>50136270</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>50136383</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>50136461</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>50136466</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>50136557</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>50136591</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>50136611</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>50136896</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>50136998</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>50137359</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>50137401</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7884</th>\n",
       "      <td>53736394</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7885</th>\n",
       "      <td>53736395</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7886</th>\n",
       "      <td>53736396</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7887</th>\n",
       "      <td>53736397</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7888</th>\n",
       "      <td>53736398</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7889</th>\n",
       "      <td>53736399</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7890</th>\n",
       "      <td>53736400</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7891</th>\n",
       "      <td>53736401</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7892</th>\n",
       "      <td>53736402</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7893</th>\n",
       "      <td>53736403</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7894</th>\n",
       "      <td>53736404</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7895</th>\n",
       "      <td>53736405</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7896</th>\n",
       "      <td>53736406</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7897</th>\n",
       "      <td>53736407</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7898</th>\n",
       "      <td>53736408</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7899</th>\n",
       "      <td>53736409</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7900</th>\n",
       "      <td>53736410</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7901</th>\n",
       "      <td>53736411</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7902</th>\n",
       "      <td>53736412</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7903</th>\n",
       "      <td>53736413</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7904</th>\n",
       "      <td>53736414</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7905</th>\n",
       "      <td>53736415</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7906</th>\n",
       "      <td>53736416</td>\n",
       "      <td>14.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7907</th>\n",
       "      <td>53736417</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7908</th>\n",
       "      <td>53736418</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7909</th>\n",
       "      <td>53736419</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7910</th>\n",
       "      <td>53736420</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7911</th>\n",
       "      <td>53736421</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7912</th>\n",
       "      <td>53736422</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7913</th>\n",
       "      <td>53736423</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7914 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      patient_id  readmission\n",
       "0       50135262          1.0\n",
       "1       50135361          7.0\n",
       "2       50135369          2.0\n",
       "3       50135375         10.0\n",
       "4       50135425          1.0\n",
       "5       50135437         41.0\n",
       "6       50135624          4.0\n",
       "7       50135735          1.0\n",
       "8       50135759          0.0\n",
       "9       50135821          4.0\n",
       "10      50135887          1.0\n",
       "11      50135891          1.0\n",
       "12      50135968          3.0\n",
       "13      50136007          0.0\n",
       "14      50136045          4.0\n",
       "15      50136072          9.0\n",
       "16      50136118          0.0\n",
       "17      50136183          1.0\n",
       "18      50136213          0.0\n",
       "19      50136270          1.0\n",
       "20      50136383          0.0\n",
       "21      50136461          2.0\n",
       "22      50136466          0.0\n",
       "23      50136557          0.0\n",
       "24      50136591          0.0\n",
       "25      50136611          0.0\n",
       "26      50136896          6.0\n",
       "27      50136998          0.0\n",
       "28      50137359          0.0\n",
       "29      50137401          1.0\n",
       "...          ...          ...\n",
       "7884    53736394          4.0\n",
       "7885    53736395          0.0\n",
       "7886    53736396          0.0\n",
       "7887    53736397          0.0\n",
       "7888    53736398          4.0\n",
       "7889    53736399          0.0\n",
       "7890    53736400          0.0\n",
       "7891    53736401          0.0\n",
       "7892    53736402          0.0\n",
       "7893    53736403          0.0\n",
       "7894    53736404          0.0\n",
       "7895    53736405          1.0\n",
       "7896    53736406          0.0\n",
       "7897    53736407          0.0\n",
       "7898    53736408          0.0\n",
       "7899    53736409          0.0\n",
       "7900    53736410          2.0\n",
       "7901    53736411          0.0\n",
       "7902    53736412          0.0\n",
       "7903    53736413          0.0\n",
       "7904    53736414          0.0\n",
       "7905    53736415          0.0\n",
       "7906    53736416         14.0\n",
       "7907    53736417          2.0\n",
       "7908    53736418          0.0\n",
       "7909    53736419          0.0\n",
       "7910    53736420          0.0\n",
       "7911    53736421          6.0\n",
       "7912    53736422          0.0\n",
       "7913    53736423          0.0\n",
       "\n",
       "[7914 rows x 2 columns]"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Y is now a dataframe that includes the number of times the patient has been readmitted within 30 days, and the patient ID. We plan to model whether or not a patient was readmitted within 30 days at all, but we also though we may be able to predict more information by modeling a discrete variable, rather than a binary (1/0) variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
