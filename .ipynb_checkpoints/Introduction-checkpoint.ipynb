{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overview of Problem"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have received Vanderbilt hospital data extracted from the Synthetic Derivative. At Vanderbilt, bioinformaticians helped to create a \"mirror image\" of electronic medical records such as those in BioVU, Vanderbilt's biorepository of DNA extracted from discarded blood collected during routine clinical testing. This mirror of the EMR is called the Synthetic Derivative, and it contains over 2 million individual patients with all clinical information available for the past 10 years. It has been scrubbed of HIPAA identifiers with an eror rate of ~0.01%, meaning that the data has been deidentified with a subject ID. \n",
    "\n",
    "The objective of this project is to employ modeling tools introduced in class to fit prediction models for patient readmission within 30 days of discharge using given data. The data includes multiple variables, detailed below in \"Data.\" Ideally, our model will be able to well predict readmission within 30 days of discharge for a patient using the admit/discharge/transfer events data. The rest of the data detials information about the patients themselves, tests and treatments they underwent at Vanderbilt, and lab results and medication. Using these variables, we hope to accurately predict readmission. This information could be very useful for actually clinicians hoping to predict which patients may need to be readmitted, and which characteristics/tests cause them to be readmitted. Once this is determined, that subset of patients could be given more attention and/or tests to prevent readmission."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Goal and Structure of Project"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This project will introduce several approaches to predictive modeling of patient readmission within 30 days of discharge. Three approaches are detailed in the following jupyter notebooks, each of which may include more than one modeling type, attempts to improve each model and test performance, and tuning of the models to increase the goodness of fit. Cross-validation will be used when appropriate, and model selection methods and/or explanations of the models chosen will be provided for each notebook. We will then justify and describe each model selection, and provide visualizations and discussions of the results. The models will be compared using goodness of fit tests and other performance characteristics. For clarification, the steps for each model notebook are listed below, and enumerated in the following 3 modeling notebooks. \n",
    "\n",
    "1. Identify the model approach(es), describe, and justify the selection\n",
    "2. Code, parameterize, and run model (including visualization)\n",
    "3. Cross-validation\n",
    "4. Goodness of fit assessments, performance characteristics (including visualization)\n",
    "5. Improvements to model/tuning of parameters; model selection methods, justification of improvements/tests\n",
    "6. Comparison of models; identification of best model\n",
    "7. Results \n",
    "8. Implications of model and conclusions\n",
    "\n",
    "We have also included a conclusions notebook that details the comparisons of the 3 model types, which ones worked and didn't work, our best model, and future directions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data and cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ADT: \n",
    "Admit/Discharge/Transfer Events. Includes the variables:\n",
    "1. \"Event\" (Admit, Transfer, or Discharge)\n",
    "2. \"Admission_date\" (date format, M/DD/YY)\n",
    "3. \"Event_Date\" (date)\n",
    "4. \"SRV_CODE\" (e.g. ORT, NEU, GMB)\n",
    "5. \"CHIEF_COMPLAINT\" (e.g. CP, CHEST PAIN, SEIZURES)\n",
    "6. \"DISCHARGE_DATE\" (date)\n",
    "\n",
    "This dataframe was cleaned by parsing the dates from strings to pandas datetime format, replacing column names and making everything lowercase for easier data parsing. The data is a little redundant; each row has an \"event,\" either an admit, transfer, or discharge, but also has the admission and discharge dates for that entire stay for that patient. In other words, the admission and discharge dates are repeated on multiple rows for the same stay: at least two rows (one for admit and one for discharge) but possibly more, depending on the number of transfers. We collapsed these rows so that each hospital stay is represented by only one row. Patient IDs may be repeated, depending on readmission rates.\n",
    "\n",
    "This data frame was used to organize the variables for each patient for each hospital stay, as well as to generate a variable for prediction. This \"y\" variable dataframe was generated by looking at one patient and their admission and discharge dates. If the patient had any admission dates within 30 days of a discharge date, this variable is given the value \"1\"; if there were none, the patient got a value of \"0.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "patient_id           0\n",
       "adt_event            0\n",
       "admission_date       2\n",
       "adt_event_date       0\n",
       "srv_code             0\n",
       "chief_complaint    265\n",
       "discharge_date       0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#   imports & variables\n",
    "###\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy  as np\n",
    "import csv\n",
    "\n",
    "data_path = \"/Users/sarahmaddox/Desktop/Data/\"\n",
    "\n",
    "\n",
    "###\n",
    "#   ADT\n",
    "### \n",
    "adt = pd.read_csv(data_path+\"FONNESBECK_ADT.csv\", na_values=[''], \n",
    "                  parse_dates=['Admission_date', 'Event_Date', 'DISCHARGE_DATE'],\n",
    "                  encoding = \"ISO-8859-1\")\n",
    "adt.head()\n",
    "\n",
    "# rename the columns and replace event strings with simpler versions\n",
    "# #todo -- expand categorical variables using get_dummies\n",
    "adt_clean = (adt\n",
    "             .rename(columns={\"RUID\": \"patient_id\", \n",
    "                              \"Event\":\"adt_event\", \n",
    "                              \"Admission_date\": \"admission_date\",\n",
    "                              \"Event_Date\": \"adt_event_date\", \n",
    "                              \"SRV_CODE\": \"srv_code\",\n",
    "                              \"CHIEF_COMPLAINT\": \"chief_complaint\", \n",
    "                              \"DISCHARGE_DATE\": \"discharge_date\"})\n",
    "             .replace({'adt_event': {'.*Admit': 'admit',\n",
    "                                     '.*Discharge': 'discharge', \n",
    "                                     '.*Transfer': 'transfer'}}, regex=True))\n",
    "\n",
    "adt_clean.head()\n",
    "\n",
    "# calculate the amount of missing data in the ADT table\n",
    "adt_clean.isnull().sum()\n",
    "\n",
    "# presumably only discharges will have discharge dates; these actual missing data\n",
    "(adt_clean[adt_clean.adt_event == 'discharge']).isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since there are only two missing admission dates, we think we can safely exclude this data. We are not using the chief_complaint because there is a wide range of complaints that are not necessarily related to the hospital stay, and can change for each hospital stay."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>patient_id</th>\n",
       "      <th>admission_date</th>\n",
       "      <th>discharge_date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>50135262</td>\n",
       "      <td>2007-02-08</td>\n",
       "      <td>2007-02-12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>50135262</td>\n",
       "      <td>2007-08-03</td>\n",
       "      <td>2007-08-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>50135262</td>\n",
       "      <td>2014-11-15</td>\n",
       "      <td>2014-11-18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>50135262</td>\n",
       "      <td>2007-08-28</td>\n",
       "      <td>2007-08-29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>50135262</td>\n",
       "      <td>2012-09-15</td>\n",
       "      <td>2012-09-22</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   patient_id admission_date discharge_date\n",
       "0    50135262     2007-02-08     2007-02-12\n",
       "1    50135262     2007-08-03     2007-08-06\n",
       "2    50135262     2014-11-15     2014-11-18\n",
       "3    50135262     2007-08-28     2007-08-29\n",
       "4    50135262     2012-09-15     2012-09-22"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame(adt_clean, columns = ['patient_id','adt_event','admission_date', 'discharge_date'])\n",
    "df = df[df.adt_event != 'transfer']\n",
    "df = df[df.adt_event != 'discharge']\n",
    "# adt_final\n",
    "df_adt = df[['patient_id','admission_date', 'discharge_date']]\n",
    "df_adt = df_adt.sort_values('admission_date')\n",
    "df_adt = df_adt.sort_values('patient_id')\n",
    "df_adt=df_adt.reset_index(drop=True)\n",
    "\n",
    "df_adt.to_csv(\"df_adt_clean.csv\")\n",
    "df_adt.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BMI: \n",
    "Body mass index measurement information.\n",
    "Includes the variables:\n",
    "1. \"BMI\" (numeric)\n",
    "2. Date_BMI (date M/DD/YY)\n",
    "3. BMI_Weight (numeric, in kg)\n",
    "4. BMI_Height (numeric, in cm)\n",
    "5. Pregnancy_Indicator (0, 1).\n",
    "\n",
    "Cleaning of the BMI dataset: We decided that BMI gave us enough information, and height and weight were a little superfluous. In order to reduce the number of possible variables in the model, we only included BMI, the date the BMI measurement was taken, and a pregnancy indicator in the final dataset for modeling. We used \"Date_BMI\" to include this data into our larger \"X\" dataset by checking where this date fell between the patient's admission and discharge dates and adding the data to that row."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###\n",
    "#   BMI\n",
    "###\n",
    "bmi = pd.read_csv(data_path+\"FONNESBECK_BMI.csv\", parse_dates=['Date_BMI'], infer_datetime_format=True)\n",
    "bmi.head()\n",
    "\n",
    "bmi_clean = (bmi\n",
    "             .rename(columns={\"RUID\": \"patient_id\", \n",
    "                              \"BMI\": \"bmi\",\n",
    "                              \"Date_BMI\": \"bmi_date\", \n",
    "                              \"BMI_Weight\": \"weight\",\n",
    "                              \"BMI_Height\": \"height\", \n",
    "                              \"Pregnancy_Indicator\": \"pregnant\"}))\n",
    "bmi_clean['bmi_date'] = pd.to_datetime(bmi_clean.bmi_date, errors='coerce')\n",
    "bmi_clean.head()\n",
    "\n",
    "# small amount of missingness\n",
    "# #todo -- possible to fill in missing if same patient\n",
    "# bmi_clean.isnull().sum()\n",
    "df_bmi = bmi_clean.drop_duplicates(subset='bmi_date')\n",
    "df_bmi = df_bmi[['patient_id', 'bmi', 'bmi_date']]\n",
    "df_bmi.head()\n",
    "bmi_clean.groupby('bmi_date',sort=True).sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BP: \n",
    "Blood pressure measurements. Includes the variables:\n",
    "1. \"SYSTOLIC\" (integer)\n",
    "2. \"DIASTOLIC\" (integer)\n",
    "3. \"Measure_date\" (M/DD/YY)\n",
    "\n",
    "The Systolic and Diastolic variables are used in the \"X\" dataset by taking a mean over all of the patients' values and recording one systolic pressure measurement and one diastolic pressure measurement per patient. We also included BPS_trend and BPD_trend variables, which is the slope of a linear regression model fit to the BP pressures over time. However, the maximum value for the trends was still very close to 0-- about 10^-13. Thus, we will have a general, mean measurement describing each patient, and will remove the trend values, since each patient's either stays constant or does not show a signficant increasing or decreasing trend.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "patient_id     0\n",
       "systolic       0\n",
       "diastolic      0\n",
       "bp_date       26\n",
       "dtype: int64"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "###\n",
    "#   BP\n",
    "###\n",
    "bp = pd.read_csv(data_path+\"FONNESBECK_BP.csv\", parse_dates=['Measure_date'], infer_datetime_format=True)\n",
    "bp.head()\n",
    "\n",
    "bp_clean = (bp\n",
    "            .rename(columns={\"RUID\": \"patient_id\", \n",
    "                             \"SYSTOLIC\": \"systolic\",\n",
    "                             \"DIASTOLIC\": \"diastolic\", \n",
    "                             \"Measure_date\": \"bp_date\"}))\n",
    "bp_clean['bp_date'] = pd.to_datetime(bp_clean.bp_date, errors='coerce')\n",
    "\n",
    "# only missing dates, may not need to address\n",
    "bp_clean.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>patient_id</th>\n",
       "      <th>systolic</th>\n",
       "      <th>diastolic</th>\n",
       "      <th>bp_date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>50135262</td>\n",
       "      <td>150</td>\n",
       "      <td>80</td>\n",
       "      <td>2005-01-09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>50135262</td>\n",
       "      <td>137</td>\n",
       "      <td>77</td>\n",
       "      <td>2007-02-08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>50135262</td>\n",
       "      <td>137</td>\n",
       "      <td>78</td>\n",
       "      <td>2007-02-08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>50135262</td>\n",
       "      <td>190</td>\n",
       "      <td>78</td>\n",
       "      <td>2007-02-08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>50135262</td>\n",
       "      <td>190</td>\n",
       "      <td>77</td>\n",
       "      <td>2007-02-08</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   patient_id  systolic  diastolic    bp_date\n",
       "0    50135262       150         80 2005-01-09\n",
       "1    50135262       137         77 2007-02-08\n",
       "2    50135262       137         78 2007-02-08\n",
       "3    50135262       190         78 2007-02-08\n",
       "4    50135262       190         77 2007-02-08"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bp_clean = bp_clean.sort_values('patient_id')\n",
    "bp_clean=bp_clean.reset_index(drop=True)\n",
    "\n",
    "bp_clean.to_csv(\"bp_clean.csv\")\n",
    "bp_clean.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/envs/bios8366/lib/python3.6/site-packages/ipykernel_launcher.py:21: FutureWarning: reshape is deprecated and will raise in a subsequent release. Please use .values.reshape(...) instead\n"
     ]
    }
   ],
   "source": [
    "from sklearn import datasets, linear_model\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "unique_ids = bp_clean.patient_id.unique()\n",
    "ps_means = list(range(len(unique_ids)))\n",
    "pd_means = list(range(len(unique_ids)))\n",
    "ps_trends = list(range(len(unique_ids)))\n",
    "pd_trends = list(range(len(unique_ids)))\n",
    "for p, count in zip(unique_ids, range(len(unique_ids))):\n",
    "#make a subsetted dataframe of just that ID\n",
    "    p_df = bp_clean[bp_clean.patient_id == p]\n",
    "    p_df=p_df.reset_index(drop=True)\n",
    "    #for each measurement in that list:\n",
    "    s_mean=p_df.systolic.mean()\n",
    "    d_mean=p_df.diastolic.mean()\n",
    "    ps_means[count]=s_mean\n",
    "    pd_means[count]=d_mean\n",
    "    #Trends in dp and sp: fit each patient's data with a linear regression and record the slope.\n",
    "    d_regr = linear_model.LinearRegression()\n",
    "    d_regr.fit(p_df.bp_date.reshape(-1, 1), p_df.diastolic.reshape(-1, 1))\n",
    "    b=d_regr.coef_.item(0)\n",
    "    pd_trends[count]=b\n",
    "\n",
    "x_bp = pd.DataFrame({'patient_id':unique_ids, \n",
    "                     'ps_mean': ps_means, 'pd_mean': pd_means,\n",
    "                     'ps_trend':ps_trends, 'pd_trend':pd_trends})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>patient_id</th>\n",
       "      <th>pd_mean</th>\n",
       "      <th>pd_trend</th>\n",
       "      <th>ps_mean</th>\n",
       "      <th>ps_trend</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>50135262</td>\n",
       "      <td>64.086464</td>\n",
       "      <td>-6.671398e-18</td>\n",
       "      <td>141.160834</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>50135361</td>\n",
       "      <td>59.877885</td>\n",
       "      <td>1.522614e-17</td>\n",
       "      <td>112.785374</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>50135369</td>\n",
       "      <td>70.011200</td>\n",
       "      <td>-1.273555e-17</td>\n",
       "      <td>115.893943</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>50135375</td>\n",
       "      <td>67.844574</td>\n",
       "      <td>-6.963159e-17</td>\n",
       "      <td>118.336822</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>50135425</td>\n",
       "      <td>56.765079</td>\n",
       "      <td>-8.611786e-17</td>\n",
       "      <td>128.038095</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   patient_id    pd_mean      pd_trend     ps_mean  ps_trend\n",
       "0    50135262  64.086464 -6.671398e-18  141.160834         0\n",
       "1    50135361  59.877885  1.522614e-17  112.785374         1\n",
       "2    50135369  70.011200 -1.273555e-17  115.893943         2\n",
       "3    50135375  67.844574 -6.963159e-17  118.336822         3\n",
       "4    50135425  56.765079 -8.611786e-17  128.038095         4"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_bp.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As mentioned above, the largest pd_trend value is about 10^-13. This was investigated for one patient below, showing that even though each blood pressure measurement varied, it was not in a significant direction. Thus, we decided to include the variance instead of the trend (slope of the linear regression)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>patient_id</th>\n",
       "      <th>systolic</th>\n",
       "      <th>diastolic</th>\n",
       "      <th>bp_date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>50135262</td>\n",
       "      <td>150</td>\n",
       "      <td>80</td>\n",
       "      <td>2005-01-09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>50135262</td>\n",
       "      <td>137</td>\n",
       "      <td>77</td>\n",
       "      <td>2007-02-08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>50135262</td>\n",
       "      <td>137</td>\n",
       "      <td>78</td>\n",
       "      <td>2007-02-08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>50135262</td>\n",
       "      <td>190</td>\n",
       "      <td>78</td>\n",
       "      <td>2007-02-08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>50135262</td>\n",
       "      <td>190</td>\n",
       "      <td>77</td>\n",
       "      <td>2007-02-08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>50135262</td>\n",
       "      <td>137</td>\n",
       "      <td>64</td>\n",
       "      <td>2007-02-08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>50135262</td>\n",
       "      <td>186</td>\n",
       "      <td>78</td>\n",
       "      <td>2007-02-08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>50135262</td>\n",
       "      <td>186</td>\n",
       "      <td>64</td>\n",
       "      <td>2007-02-08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>50135262</td>\n",
       "      <td>190</td>\n",
       "      <td>64</td>\n",
       "      <td>2007-02-08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>50135262</td>\n",
       "      <td>186</td>\n",
       "      <td>77</td>\n",
       "      <td>2007-02-08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>50135262</td>\n",
       "      <td>160</td>\n",
       "      <td>72</td>\n",
       "      <td>2007-02-09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>50135262</td>\n",
       "      <td>161</td>\n",
       "      <td>56</td>\n",
       "      <td>2007-02-09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>50135262</td>\n",
       "      <td>160</td>\n",
       "      <td>49</td>\n",
       "      <td>2007-02-09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>50135262</td>\n",
       "      <td>154</td>\n",
       "      <td>61</td>\n",
       "      <td>2011-02-15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>50135262</td>\n",
       "      <td>161</td>\n",
       "      <td>49</td>\n",
       "      <td>2007-02-09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>50135262</td>\n",
       "      <td>160</td>\n",
       "      <td>56</td>\n",
       "      <td>2007-02-09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>50135262</td>\n",
       "      <td>146</td>\n",
       "      <td>49</td>\n",
       "      <td>2007-02-09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>50135262</td>\n",
       "      <td>146</td>\n",
       "      <td>56</td>\n",
       "      <td>2007-02-09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>50135262</td>\n",
       "      <td>120</td>\n",
       "      <td>72</td>\n",
       "      <td>2007-02-09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>50135262</td>\n",
       "      <td>161</td>\n",
       "      <td>72</td>\n",
       "      <td>2007-02-09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>50135262</td>\n",
       "      <td>120</td>\n",
       "      <td>56</td>\n",
       "      <td>2007-02-09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>50135262</td>\n",
       "      <td>120</td>\n",
       "      <td>49</td>\n",
       "      <td>2007-02-09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>50135262</td>\n",
       "      <td>143</td>\n",
       "      <td>72</td>\n",
       "      <td>2007-02-10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>50135262</td>\n",
       "      <td>143</td>\n",
       "      <td>52</td>\n",
       "      <td>2007-02-10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>50135262</td>\n",
       "      <td>139</td>\n",
       "      <td>49</td>\n",
       "      <td>2007-02-10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>50135262</td>\n",
       "      <td>103</td>\n",
       "      <td>52</td>\n",
       "      <td>2007-02-10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>50135262</td>\n",
       "      <td>134</td>\n",
       "      <td>72</td>\n",
       "      <td>2007-02-10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>50135262</td>\n",
       "      <td>146</td>\n",
       "      <td>72</td>\n",
       "      <td>2007-02-09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>50135262</td>\n",
       "      <td>133</td>\n",
       "      <td>55</td>\n",
       "      <td>2007-02-11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>50135262</td>\n",
       "      <td>134</td>\n",
       "      <td>49</td>\n",
       "      <td>2007-02-10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3856</th>\n",
       "      <td>50135262</td>\n",
       "      <td>134</td>\n",
       "      <td>60</td>\n",
       "      <td>2014-11-15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3857</th>\n",
       "      <td>50135262</td>\n",
       "      <td>128</td>\n",
       "      <td>50</td>\n",
       "      <td>2014-11-16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3858</th>\n",
       "      <td>50135262</td>\n",
       "      <td>131</td>\n",
       "      <td>50</td>\n",
       "      <td>2014-11-16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3859</th>\n",
       "      <td>50135262</td>\n",
       "      <td>176</td>\n",
       "      <td>83</td>\n",
       "      <td>2010-10-29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3860</th>\n",
       "      <td>50135262</td>\n",
       "      <td>113</td>\n",
       "      <td>59</td>\n",
       "      <td>2014-11-17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3861</th>\n",
       "      <td>50135262</td>\n",
       "      <td>131</td>\n",
       "      <td>56</td>\n",
       "      <td>2014-11-16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3862</th>\n",
       "      <td>50135262</td>\n",
       "      <td>113</td>\n",
       "      <td>60</td>\n",
       "      <td>2014-11-17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3863</th>\n",
       "      <td>50135262</td>\n",
       "      <td>113</td>\n",
       "      <td>67</td>\n",
       "      <td>2014-11-17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3864</th>\n",
       "      <td>50135262</td>\n",
       "      <td>147</td>\n",
       "      <td>69</td>\n",
       "      <td>2014-11-17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3865</th>\n",
       "      <td>50135262</td>\n",
       "      <td>147</td>\n",
       "      <td>60</td>\n",
       "      <td>2014-11-17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3866</th>\n",
       "      <td>50135262</td>\n",
       "      <td>150</td>\n",
       "      <td>69</td>\n",
       "      <td>2014-11-17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3867</th>\n",
       "      <td>50135262</td>\n",
       "      <td>150</td>\n",
       "      <td>60</td>\n",
       "      <td>2014-11-17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3868</th>\n",
       "      <td>50135262</td>\n",
       "      <td>131</td>\n",
       "      <td>54</td>\n",
       "      <td>2014-11-16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3869</th>\n",
       "      <td>50135262</td>\n",
       "      <td>113</td>\n",
       "      <td>69</td>\n",
       "      <td>2014-11-17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3870</th>\n",
       "      <td>50135262</td>\n",
       "      <td>150</td>\n",
       "      <td>67</td>\n",
       "      <td>2014-11-17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3871</th>\n",
       "      <td>50135262</td>\n",
       "      <td>134</td>\n",
       "      <td>67</td>\n",
       "      <td>2014-11-17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3872</th>\n",
       "      <td>50135262</td>\n",
       "      <td>134</td>\n",
       "      <td>69</td>\n",
       "      <td>2014-11-17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3873</th>\n",
       "      <td>50135262</td>\n",
       "      <td>150</td>\n",
       "      <td>59</td>\n",
       "      <td>2014-11-17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3874</th>\n",
       "      <td>50135262</td>\n",
       "      <td>124</td>\n",
       "      <td>58</td>\n",
       "      <td>2014-11-18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3875</th>\n",
       "      <td>50135262</td>\n",
       "      <td>130</td>\n",
       "      <td>62</td>\n",
       "      <td>2013-12-23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3876</th>\n",
       "      <td>50135262</td>\n",
       "      <td>146</td>\n",
       "      <td>70</td>\n",
       "      <td>2012-12-17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3877</th>\n",
       "      <td>50135262</td>\n",
       "      <td>132</td>\n",
       "      <td>82</td>\n",
       "      <td>2011-12-13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3878</th>\n",
       "      <td>50135262</td>\n",
       "      <td>147</td>\n",
       "      <td>67</td>\n",
       "      <td>2014-11-17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3879</th>\n",
       "      <td>50135262</td>\n",
       "      <td>147</td>\n",
       "      <td>59</td>\n",
       "      <td>2014-11-17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3880</th>\n",
       "      <td>50135262</td>\n",
       "      <td>150</td>\n",
       "      <td>68</td>\n",
       "      <td>2007-12-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3881</th>\n",
       "      <td>50135262</td>\n",
       "      <td>134</td>\n",
       "      <td>59</td>\n",
       "      <td>2014-11-17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3882</th>\n",
       "      <td>50135262</td>\n",
       "      <td>110</td>\n",
       "      <td>64</td>\n",
       "      <td>2004-11-30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3883</th>\n",
       "      <td>50135262</td>\n",
       "      <td>132</td>\n",
       "      <td>86</td>\n",
       "      <td>2011-11-28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3884</th>\n",
       "      <td>50135262</td>\n",
       "      <td>134</td>\n",
       "      <td>60</td>\n",
       "      <td>2014-11-17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3885</th>\n",
       "      <td>50135262</td>\n",
       "      <td>160</td>\n",
       "      <td>70</td>\n",
       "      <td>2010-12-02</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3886 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      patient_id  systolic  diastolic    bp_date\n",
       "0       50135262       150         80 2005-01-09\n",
       "1       50135262       137         77 2007-02-08\n",
       "2       50135262       137         78 2007-02-08\n",
       "3       50135262       190         78 2007-02-08\n",
       "4       50135262       190         77 2007-02-08\n",
       "5       50135262       137         64 2007-02-08\n",
       "6       50135262       186         78 2007-02-08\n",
       "7       50135262       186         64 2007-02-08\n",
       "8       50135262       190         64 2007-02-08\n",
       "9       50135262       186         77 2007-02-08\n",
       "10      50135262       160         72 2007-02-09\n",
       "11      50135262       161         56 2007-02-09\n",
       "12      50135262       160         49 2007-02-09\n",
       "13      50135262       154         61 2011-02-15\n",
       "14      50135262       161         49 2007-02-09\n",
       "15      50135262       160         56 2007-02-09\n",
       "16      50135262       146         49 2007-02-09\n",
       "17      50135262       146         56 2007-02-09\n",
       "18      50135262       120         72 2007-02-09\n",
       "19      50135262       161         72 2007-02-09\n",
       "20      50135262       120         56 2007-02-09\n",
       "21      50135262       120         49 2007-02-09\n",
       "22      50135262       143         72 2007-02-10\n",
       "23      50135262       143         52 2007-02-10\n",
       "24      50135262       139         49 2007-02-10\n",
       "25      50135262       103         52 2007-02-10\n",
       "26      50135262       134         72 2007-02-10\n",
       "27      50135262       146         72 2007-02-09\n",
       "28      50135262       133         55 2007-02-11\n",
       "29      50135262       134         49 2007-02-10\n",
       "...          ...       ...        ...        ...\n",
       "3856    50135262       134         60 2014-11-15\n",
       "3857    50135262       128         50 2014-11-16\n",
       "3858    50135262       131         50 2014-11-16\n",
       "3859    50135262       176         83 2010-10-29\n",
       "3860    50135262       113         59 2014-11-17\n",
       "3861    50135262       131         56 2014-11-16\n",
       "3862    50135262       113         60 2014-11-17\n",
       "3863    50135262       113         67 2014-11-17\n",
       "3864    50135262       147         69 2014-11-17\n",
       "3865    50135262       147         60 2014-11-17\n",
       "3866    50135262       150         69 2014-11-17\n",
       "3867    50135262       150         60 2014-11-17\n",
       "3868    50135262       131         54 2014-11-16\n",
       "3869    50135262       113         69 2014-11-17\n",
       "3870    50135262       150         67 2014-11-17\n",
       "3871    50135262       134         67 2014-11-17\n",
       "3872    50135262       134         69 2014-11-17\n",
       "3873    50135262       150         59 2014-11-17\n",
       "3874    50135262       124         58 2014-11-18\n",
       "3875    50135262       130         62 2013-12-23\n",
       "3876    50135262       146         70 2012-12-17\n",
       "3877    50135262       132         82 2011-12-13\n",
       "3878    50135262       147         67 2014-11-17\n",
       "3879    50135262       147         59 2014-11-17\n",
       "3880    50135262       150         68 2007-12-03\n",
       "3881    50135262       134         59 2014-11-17\n",
       "3882    50135262       110         64 2004-11-30\n",
       "3883    50135262       132         86 2011-11-28\n",
       "3884    50135262       134         60 2014-11-17\n",
       "3885    50135262       160         70 2010-12-02\n",
       "\n",
       "[3886 rows x 4 columns]"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bp_clean.loc[bp_clean.patient_id == 50135262]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "import statsmodels.formula.api as smf\n",
    "from sklearn import datasets, linear_model\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "unique_ids = bp_clean.patient_id.unique()\n",
    "ps_means = list(range(len(unique_ids)))\n",
    "pd_means = list(range(len(unique_ids)))\n",
    "ps_variance = list(range(len(unique_ids)))\n",
    "pd_variance = list(range(len(unique_ids)))\n",
    "for p, count in zip(unique_ids, range(len(unique_ids))):\n",
    "#make a subsetted dataframe of just that ID\n",
    "    p_df = bp_clean[bp_clean.patient_id == p]\n",
    "    p_df=p_df.reset_index(drop=True)\n",
    "    #for each measurement in that list:\n",
    "    s_mean=p_df.systolic.mean()\n",
    "    d_mean=p_df.diastolic.mean()\n",
    "    ps_means[count]=s_mean\n",
    "    pd_means[count]=d_mean\n",
    "    pd_variance[count]=p_df.diastolic.std()\n",
    "    ps_variance[count]=p_df.systolic.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "bp_full_clean = pd.DataFrame({'patient_id':unique_ids, \n",
    "                     'ps_mean': ps_means, 'pd_mean': pd_means,\n",
    "                     'ps_std':ps_variance, 'pd_std':pd_variance})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>patient_id</th>\n",
       "      <th>pd_mean</th>\n",
       "      <th>pd_std</th>\n",
       "      <th>ps_mean</th>\n",
       "      <th>ps_std</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>50135262</td>\n",
       "      <td>64.086464</td>\n",
       "      <td>13.579633</td>\n",
       "      <td>141.160834</td>\n",
       "      <td>20.377205</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>50135361</td>\n",
       "      <td>59.877885</td>\n",
       "      <td>12.678492</td>\n",
       "      <td>112.785374</td>\n",
       "      <td>18.694088</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>50135369</td>\n",
       "      <td>70.011200</td>\n",
       "      <td>11.986641</td>\n",
       "      <td>115.893943</td>\n",
       "      <td>17.587347</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>50135375</td>\n",
       "      <td>67.844574</td>\n",
       "      <td>12.547771</td>\n",
       "      <td>118.336822</td>\n",
       "      <td>21.254275</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>50135425</td>\n",
       "      <td>56.765079</td>\n",
       "      <td>9.300600</td>\n",
       "      <td>128.038095</td>\n",
       "      <td>16.444496</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   patient_id    pd_mean     pd_std     ps_mean     ps_std\n",
       "0    50135262  64.086464  13.579633  141.160834  20.377205\n",
       "1    50135361  59.877885  12.678492  112.785374  18.694088\n",
       "2    50135369  70.011200  11.986641  115.893943  17.587347\n",
       "3    50135375  67.844574  12.547771  118.336822  21.254275\n",
       "4    50135425  56.765079   9.300600  128.038095  16.444496"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bp_full_clean.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MED: \n",
    "Medications information, including dose and duration.\n",
    "Includes the variables:\n",
    "1. \"Entry_Date\" (date M/DD/YY)\t\n",
    "2. \"Drug_Name\" (common drug name, string)\t\n",
    "3. \"DRUG_FORM\" (if drug comes in multiple forms, this describes which form is given. E.g. nebulizer versus inhaler for albuterol)\t\n",
    "4. \"DRUG_STRENGTH\" (mL, or NA)\n",
    "5. \"Route\" (Route of drug administration; e.g. IV, FLUSH, PO)\n",
    "6. \"Dose_Amt\" (Amount of drug, variable units; g, ML/HR, units)\n",
    "7. \"Drug_Freq\" (number of times given/how the drug is given; e.g. twice daily, once, Q1H PRN)\n",
    "8. \"Duration\" (length of time drug is given; e.g. months, days, etc)\n",
    "\n",
    "Cleaning of the MED dataset: From this dataset, we used Entry_date to include the data in our larger \"X\" data set. We included Drug_Name and dose amount, combined to be one variable. No other information from this dataset was used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###\n",
    "#   MED\n",
    "###\n",
    "med = pd.read_csv(data_path+\"FONNESBECK_MED.csv\", parse_dates=['Entry_Date'], infer_datetime_format=True)\n",
    "med.head()\n",
    "\n",
    "med_clean = (med\n",
    "             .rename(columns={\"RUID\": \"patient_id\", \n",
    "                              \"Entry_Date\": \"drug_entry_date\",\n",
    "                              \"Drug_Name\": \"drug_name\", \n",
    "                              \"DRUG_FORM\": \"drug_form\",\n",
    "                              \"DRUG_STRENGTH\": \"drug_strength\",\n",
    "                              \"Route\": \"drug_route\",\n",
    "                              \"Dose_Amt\": \"drug_dose\",\n",
    "                              \"Drug_Freq\": \"drug_freq\",\n",
    "                              \"Duration\": \"drug_duration\"}))\n",
    "med_clean.head()\n",
    "\n",
    "# lots of missing data in this table\n",
    "# many cols likely uninformative; drug_name might be most useful\n",
    "med_clean.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CPT: \n",
    "Procedure codes. Variables include:\n",
    "1. \"CPT_code\" (integer in most cases to describe categorical data)\n",
    "2. \"Event_date\" (M/DD/YY)\n",
    "\n",
    "This data was included in models that could predict using categorical data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###\n",
    "#   CPT\n",
    "###\n",
    "cpt = pd.read_csv(data_path+\"FONNESBECK_CPT.csv\", parse_dates=['Event_date'], infer_datetime_format=True)\n",
    "cpt.head()\n",
    "\n",
    "cpt_clean = (cpt\n",
    "             .rename(columns={\"RUID\": \"patient_id\", \n",
    "                              \"CPT_Code\": \"cpt_code\",\n",
    "                              \"Event_date\": \"cpt_event_date\"}))\n",
    "cpt_clean.head()\n",
    "\n",
    "# no missing data\n",
    "cpt_clean.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### EGFR: \n",
    "Estimated Glomerular Filtration Rate measurements, used to screen for kidney damage. Obtained from a creatine lab. Includes the variables:\n",
    "1. \"EGFR\" (continuous data)\n",
    "2. \"egfr_date\" (date M/DD/YY)\n",
    "\n",
    "Again, we included this in the X dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ICD9: \n",
    "Coding of diagnosed diseases and health problems. This is an international standard for classifying diseases, including nuanced classifications of a wide variety of signs, symptoms, abnormal findings, complaints, social circumstances, and external causes of injury or disease. \n",
    "\n",
    "1. \"ICD9_Code\" (code for each disease/health problem)\n",
    "2. \"Event_date\"\n",
    "\n",
    "This data is included as categorical data in our models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###\n",
    "#   ICD9\n",
    "###\n",
    "icd9 = pd.read_csv(data_path+\"FONNESBECK_ICD9.csv\", parse_dates=['Event_date'], infer_datetime_format=True)\n",
    "icd9.head()\n",
    "\n",
    "icd9_clean = (icd9\n",
    "              .rename(columns={\"RUID\": \"patient_id\", \n",
    "                               \"ICD9_Code\": \"icd9_code\",\n",
    "                               \"Event_date\": \"icd9_event_date\"}))\n",
    "icd9_clean.head()\n",
    "\n",
    "# no missing data\n",
    "icd9_clean.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LAB: \n",
    "lab results, including the variables:\n",
    "1. \"Lab_name\" (Abbreviated name of lab test)\n",
    "2. \"Lab_date\" (date)\n",
    "3. \"Lab_value\" (result of test; may be numerical or categorical, such as blood type)\n",
    "\n",
    "This data was incorporated into our large dataset as categorical data. This information is hard (and somewhat unneccessary) to add to our models; for example, we do not expect blood type to have an effect on rate of readmission. For this reason, the data was not investigated as much as the other datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###\n",
    "#   LAB\n",
    "###\n",
    "lab = pd.read_csv(data_path+\"FONNESBECK_LAB.csv\", parse_dates=['Lab_date'], \n",
    "                  infer_datetime_format=True, quoting=csv.QUOTE_NONE, na_values=['>'])\n",
    "lab.head()\n",
    "\n",
    "lab_clean = (lab\n",
    "             .rename(columns={\"RUID\": \"patient_id\", \n",
    "                              \"Lab_name\": \"short_lab_name\",\n",
    "                              \"Lab_date\": \"lab_date\", \n",
    "                              \"Lab_value\": \"lab_value\"}))\n",
    "lab_clean.head()\n",
    "\n",
    "# decent number of missing lab values\n",
    "# may be able to impute missing values if same patient \n",
    "lab_clean.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Phenotype: \n",
    "Patient attributes, including sex, race, and dates of birth and death.\n",
    "Includes the variables: \n",
    "1. \"Sex\" (F or M) \n",
    "2. \"DOB\" (date of birth)\n",
    "3. \"DOD\" (date of death)\n",
    "4. \"Race\" (W = white, B = black, A = Asian, N = Native American, H = hispanic, U = unidentified). \n",
    "\n",
    "Cleaning of the Phenotype dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "###\n",
    "#   PHENOTYPE\n",
    "###\n",
    "phenotype = pd.read_csv(data_path+\"FONNESBECK_phenotype.csv\", parse_dates=['DOB', 'DOD'], infer_datetime_format=True)\n",
    "phenotype.head()\n",
    "\n",
    "phenotype_clean = (phenotype\n",
    "                   .rename(columns={\"RUID\": \"patient_id\", \n",
    "                                    \"Sex\": \"sex\",\n",
    "                                    \"DOB\": \"DOB\", \n",
    "                                    \"DOD\": \"DOD\",\n",
    "                                    \"Race\": \"race\"})\n",
    "                   .replace({'sex':  {'F': 0,'M': 1, 'U': 'NaN', '.': 'NaN', 'NA': 'NaN'}}))\n",
    "phenotype_clean.head()\n",
    "\n",
    "# lots of missing DOBs and sex\n",
    "phenotype_clean.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating the X dataset for prediction: Variables of Interest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After all of the above is done, we have each cleaned and organized dataset, and the ADT data is arranged into a dataframe with patient ID, admission date, and discharge date. Thus, each patient ID may be repeated for multiple rows, depending on how often they were admitted, but each visit should only be recorded once in its own row. To make a large dataset with all of the information we want to include for modeling, we will add data from the other datasets using the dates in those data sets. We will parse the other data sets (for example, BMI), by date (Date_BMI). For each event in the BMI dataset, we will find the matching patient by ID. We will then find the correct column by comparing the date of the measurement (Date_BMI) to the Admission date and Discharge date in each row for that patient (i.e., adding the BMI measurement to the column where the patient ID matches and Admission_date $\\leq$ Date_BMI $\\leq$ Discharge_date.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating the Y variable dataset for prediction: Rate of Readmission"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We used the same cleaned and organized ABT dataset to create a \"Y\" dataset that will be used to check our predictions of readmissions within 30 days of discharge. For each patient, we ran a for loop through the rows. Each row has a different discharge date, and this date was compared to all of the other admission dates to see if any admission dates were within 30 days of the discharge. If there is such a date, the loop is broken, the patient received a \"1\" value for a \"readmitted\" variable, and the next patient is investigated. This will give us a binary variable corresponding to the patients that were readmitted within 30 days at least once at any time. When building our models, we can use this information to check the accuracy of our models and for cross-validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>patient_id</th>\n",
       "      <th>admission_date</th>\n",
       "      <th>discharge_date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>50135262</td>\n",
       "      <td>2007-02-08</td>\n",
       "      <td>2007-02-12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>50135262</td>\n",
       "      <td>2007-08-03</td>\n",
       "      <td>2007-08-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>50135262</td>\n",
       "      <td>2014-11-15</td>\n",
       "      <td>2014-11-18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>50135262</td>\n",
       "      <td>2007-08-28</td>\n",
       "      <td>2007-08-29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>50135262</td>\n",
       "      <td>2012-09-15</td>\n",
       "      <td>2012-09-22</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   patient_id admission_date discharge_date\n",
       "0    50135262     2007-02-08     2007-02-12\n",
       "1    50135262     2007-08-03     2007-08-06\n",
       "2    50135262     2014-11-15     2014-11-18\n",
       "3    50135262     2007-08-28     2007-08-29\n",
       "4    50135262     2012-09-15     2012-09-22"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = pd.read_csv(\"df_adt_clean.csv\", parse_dates=['admission_date', 'discharge_date'], index_col=0)\n",
    "x.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the above dataframe, I can compare discharge dates and admission dates for each patient. I will write a loop below that looks patient by patient. For each patient, I will loop through the discharge dates and compare them to the admission dates. If any are within 30 days of discharge, I will break from the inner loop, give the patient a \"1\", and move to the next patient."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([50135262, 50135361, 50135369, ..., 53736421, 53736422, 53736423])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unique_ids = x.patient_id.unique()\n",
    "unique_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7914\n"
     ]
    }
   ],
   "source": [
    "patients_readmitted = np.zeros(len(unique_ids))\n",
    "print(len(unique_ids))\n",
    "for p, count in zip(unique_ids, range(len(unique_ids))):\n",
    "#for p in [50135262]:\n",
    "#make a subsetted dataframe of just that ID\n",
    "    p_df = x[x.patient_id == p]\n",
    "    p_df=p_df.reset_index(drop=True)\n",
    "    #for each discharge_date in that list:\n",
    "    for i in range(len(p_df)):\n",
    "    #compare the discharge date to all of the admission dates in list\n",
    "        discharge = p_df.loc[i][\"discharge_date\"]\n",
    "        for j in range(len(p_df)):\n",
    "            readmit = p_df.loc[j][\"admission_date\"]\n",
    "            if (readmit - discharge > pd.to_timedelta('0 days')) and (readmit - discharge < pd.to_timedelta('30 days')):\n",
    "                patients_readmitted[count]=patients_readmitted[count]+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = pd.DataFrame({'patient_id':unique_ids, 'readmission':patients_readmitted})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>patient_id</th>\n",
       "      <th>readmission</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>50135262</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>50135361</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>50135369</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>50135375</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>50135425</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   patient_id  readmission\n",
       "0    50135262          1.0\n",
       "1    50135361          7.0\n",
       "2    50135369          2.0\n",
       "3    50135375         10.0\n",
       "4    50135425          1.0"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Y is now a dataframe that includes the number of times the patient has been readmitted within 30 days, and the patient ID. We plan to model whether or not a patient was readmitted within 30 days at all, but we also though we may be able to predict more information by modeling a discrete variable, rather than a binary (1/0) variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
