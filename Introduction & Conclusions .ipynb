{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overview of Problem"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have received Vanderbilt hospital data extracted from the Synthetic Derivative. At Vanderbilt, bioinformaticians helped to create a \"mirror image\" of electronic medical records such as those in BioVU, Vanderbilt's biorepository of DNA extracted from discarded blood collected during routine clinical testing. This mirror of the EMR is called the Synthetic Derivative, and it contains over 2 million individual patients with all clinical information available for the past 10 years. It has been scrubbed of HIPAA identifiers with an eror rate of ~0.01%, meaning that the data has been deidentified with a subject ID. \n",
    "\n",
    "The objective of this project is to employ modeling tools introduced in class to fit prediction models for patient readmission within 30 days of discharge using given data. The data includes multiple variables, detailed below in \"Data.\" Ideally, our model will be able to well predict readmission within 30 days of discharge for a patient using the admit/discharge/transfer events data. The rest of the data detials information about the patients themselves, tests and treatments they underwent at Vanderbilt, and lab results and medication. Using these variables, we hope to accurately predict readmission. This information could be very useful for actually clinicians hoping to predict which patients may need to be readmitted, and which characteristics/tests cause them to be readmitted. Once this is determined, that subset of patients could be given more attention and/or tests to prevent readmission."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Goal and Structure of Project"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This project will introduce several approaches to predictive modeling of patient readmission within 30 days of discharge. Three approaches are detailed in the following jupyter notebooks, each of which may include more than one modeling type, attempts to improve each model and test performance, and tuning of the models to increase the goodness of fit. Cross-validation will be used when appropriate, and model selection methods and/or explanations of the models chosen will be provided for each notebook. We will then justify and describe each model selection, and provide visualizations and discussions of the results. The models will be compared using goodness of fit tests and other performance characteristics. For clarification, the steps for each model notebook are listed below, and enumerated in the following 3 modeling notebooks. \n",
    "\n",
    "1. Identify the model approach(es), describe, and justify the selection\n",
    "2. Code, parameterize, and run model (including visualization)\n",
    "3. Cross-validation\n",
    "4. Goodness of fit assessments, performance characteristics (including visualization)\n",
    "5. Improvements to model/tuning of parameters; model selection methods, justification of improvements/tests\n",
    "6. Comparison of models; identification of best model\n",
    "7. Results and Implications\n",
    "\n",
    "We have also included a conclusions notebook that details the comparisons of the 3 model types, which ones worked and didn't work, our best model, and future directions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data and cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import statsmodels.formula.api as smf\n",
    "from sklearn import datasets, linear_model\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy  as np\n",
    "import csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ADT: \n",
    "Admit/Discharge/Transfer Events. Includes the variables:\n",
    "1. \"Event\" (Admit, Transfer, or Discharge)\n",
    "2. \"Admission_date\" (date format, M/DD/YY)\n",
    "3. \"Event_Date\" (date)\n",
    "4. \"SRV_CODE\" (e.g. ORT, NEU, GMB)\n",
    "5. \"CHIEF_COMPLAINT\" (e.g. CP, CHEST PAIN, SEIZURES)\n",
    "6. \"DISCHARGE_DATE\" (date)\n",
    "\n",
    "This dataframe was cleaned by parsing the dates from strings to pandas datetime format, replacing column names and making everything lowercase for easier data parsing. The data is a little redundant; each row has an \"event,\" either an admit, transfer, or discharge, but also has the admission and discharge dates for that entire stay for that patient. In other words, the admission and discharge dates are repeated on multiple rows for the same stay: at least two rows (one for admit and one for discharge) but possibly more, depending on the number of transfers. We collapsed these rows so that each hospital stay is represented by only one row. Patient IDs may be repeated, depending on readmission rates.\n",
    "\n",
    "This data frame was used to organize the variables for each patient for each hospital stay, as well as to generate a variable for prediction. This \"y\" variable dataframe was generated by looking at one patient and their admission and discharge dates. If the patient had any admission dates within 30 days of a discharge date, this variable is given the value \"1\"; if there were none, the patient got a value of \"0.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = \"/Users/geenaildefonso/PData/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "patient_id           0\n",
       "adt_event            0\n",
       "admission_date       2\n",
       "adt_event_date       0\n",
       "srv_code             0\n",
       "chief_complaint    265\n",
       "discharge_date       0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "###\n",
    "#   ADT\n",
    "### \n",
    "adt = pd.read_csv(data_path+\"FONNESBECK_ADT.csv\", na_values=[''], \n",
    "                  parse_dates=['Admission_date', 'Event_Date', 'DISCHARGE_DATE'],\n",
    "                  encoding = \"ISO-8859-1\")\n",
    "adt.head()\n",
    "\n",
    "# rename the columns and replace event strings with simpler versions\n",
    "# #todo -- expand categorical variables using get_dummies\n",
    "adt_clean = (adt\n",
    "             .rename(columns={\"RUID\": \"patient_id\", \n",
    "                              \"Event\":\"adt_event\", \n",
    "                              \"Admission_date\": \"admission_date\",\n",
    "                              \"Event_Date\": \"adt_event_date\", \n",
    "                              \"SRV_CODE\": \"srv_code\",\n",
    "                              \"CHIEF_COMPLAINT\": \"chief_complaint\", \n",
    "                              \"DISCHARGE_DATE\": \"discharge_date\"})\n",
    "             .replace({'adt_event': {'.*Admit': 'admit',\n",
    "                                     '.*Discharge': 'discharge', \n",
    "                                     '.*Transfer': 'transfer'}}, regex=True))\n",
    "\n",
    "adt_clean.head()\n",
    "\n",
    "# calculate the amount of missing data in the ADT table\n",
    "adt_clean.isnull().sum()\n",
    "\n",
    "# presumably only discharges will have discharge dates; these actual missing data\n",
    "(adt_clean[adt_clean.adt_event == 'discharge']).isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since there are only two missing admission dates, we think we can safely exclude this data. We are not using the chief_complaint because there is a wide range of complaints that are not necessarily related to the hospital stay, and can change for each hospital stay."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>patient_id</th>\n",
       "      <th>admission_date</th>\n",
       "      <th>discharge_date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>50135262</td>\n",
       "      <td>2007-02-08</td>\n",
       "      <td>2007-02-12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>50135262</td>\n",
       "      <td>2007-08-03</td>\n",
       "      <td>2007-08-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>50135262</td>\n",
       "      <td>2014-11-15</td>\n",
       "      <td>2014-11-18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>50135262</td>\n",
       "      <td>2007-08-28</td>\n",
       "      <td>2007-08-29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>50135262</td>\n",
       "      <td>2012-09-15</td>\n",
       "      <td>2012-09-22</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   patient_id admission_date discharge_date\n",
       "0    50135262     2007-02-08     2007-02-12\n",
       "1    50135262     2007-08-03     2007-08-06\n",
       "2    50135262     2014-11-15     2014-11-18\n",
       "3    50135262     2007-08-28     2007-08-29\n",
       "4    50135262     2012-09-15     2012-09-22"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame(adt_clean, columns = ['patient_id','adt_event','admission_date', 'discharge_date'])\n",
    "df = df[df.adt_event != 'transfer']\n",
    "df = df[df.adt_event != 'discharge']\n",
    "# adt_final\n",
    "df_adt = df[['patient_id','admission_date', 'discharge_date']]\n",
    "df_adt = df_adt.sort_values('admission_date')\n",
    "df_adt = df_adt.sort_values('patient_id')\n",
    "df_adt=df_adt.reset_index(drop=True)\n",
    "\n",
    "df_adt.to_csv(data_path+\"df_adt_clean.csv\")\n",
    "df_adt.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BMI: \n",
    "Body mass index measurement information.\n",
    "Includes the variables:\n",
    "1. \"BMI\" (numeric)\n",
    "2. Date_BMI (date M/DD/YY)\n",
    "3. BMI_Weight (numeric, in kg)\n",
    "4. BMI_Height (numeric, in cm)\n",
    "5. Pregnancy_Indicator (0, 1).\n",
    "\n",
    "Cleaning of the BMI dataset: We decided that BMI gave us enough information, and height and weight were a little superfluous. In order to reduce the number of possible variables in the model, we only included BMI, the date the BMI measurement was taken, and a pregnancy indicator in the final dataset for modeling. We used \"Date_BMI\" to include this data into our larger \"X\" dataset by checking where this date fell between the patient's admission and discharge dates and adding the data to that row."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>patient_id</th>\n",
       "      <th>bmi</th>\n",
       "      <th>bmi_date</th>\n",
       "      <th>pregnant</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>50135262</td>\n",
       "      <td>41.43</td>\n",
       "      <td>2005-01-09</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>50135262</td>\n",
       "      <td>22.86</td>\n",
       "      <td>2011-02-11</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>50135262</td>\n",
       "      <td>43.07</td>\n",
       "      <td>2011-02-12</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>50135262</td>\n",
       "      <td>41.13</td>\n",
       "      <td>2011-02-13</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>50135262</td>\n",
       "      <td>40.29</td>\n",
       "      <td>2011-02-14</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   patient_id    bmi   bmi_date  pregnant\n",
       "0    50135262  41.43 2005-01-09         0\n",
       "1    50135262  22.86 2011-02-11         0\n",
       "2    50135262  43.07 2011-02-12         0\n",
       "5    50135262  41.13 2011-02-13         0\n",
       "7    50135262  40.29 2011-02-14         0"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "###\n",
    "#   BMI\n",
    "###\n",
    "bmi = pd.read_csv(data_path+\"FONNESBECK_BMI.csv\", parse_dates=['Date_BMI'], infer_datetime_format=True)\n",
    "bmi.head()\n",
    "\n",
    "bmi_clean = (bmi\n",
    "             .rename(columns={\"RUID\": \"patient_id\", \n",
    "                              \"BMI\": \"bmi\",\n",
    "                              \"Date_BMI\": \"bmi_date\", \n",
    "                              \"BMI_Weight\": \"weight\",\n",
    "                              \"BMI_Height\": \"height\", \n",
    "                              \"Pregnancy_Indicator\": \"pregnant\"}))\n",
    "bmi_clean['bmi_date'] = pd.to_datetime(bmi_clean.bmi_date, errors='coerce')\n",
    "bmi_clean.head()\n",
    "\n",
    "# small amount of missingness\n",
    "# #todo -- possible to fill in missing if same patient\n",
    "# bmi_clean.isnull().sum()\n",
    "df_bmi = bmi_clean.drop_duplicates(subset='bmi_date')\n",
    "df_bmi = df_bmi[['patient_id', 'bmi', 'bmi_date','pregnant']].dropna()\n",
    "df_bmi.head()\n",
    "# bmi_clean.groupby('bmi_date',sort=True).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/geenaildefonso/anaconda/envs/bios8366/lib/python3.6/site-packages/ipykernel_launcher.py:19: FutureWarning: reshape is deprecated and will raise in a subsequent release. Please use .values.reshape(...) instead\n"
     ]
    }
   ],
   "source": [
    "unique_ids = df_bmi.patient_id.unique()\n",
    "ps_means = list(range(len(unique_ids)))\n",
    "ps_std = list(range(len(unique_ids)))\n",
    "ps_trends = list(range(len(unique_ids)))\n",
    "# pd_trends = list(range(len(unique_ids)))\n",
    "for p, count in zip(unique_ids, range(len(unique_ids))):\n",
    "#make a subsetted dataframe of just that ID\n",
    "    p_df = df_bmi[df_bmi.patient_id == p]\n",
    "    p_df=p_df.reset_index(drop=True)\n",
    "    #for each measurement in that list:\n",
    "    s_mean=p_df.bmi.mean()\n",
    "    s_std=p_df.bmi.std()\n",
    "#     d_mean=p_df.diastolic.mean()\n",
    "    ps_means[count]=s_mean\n",
    "    ps_std[count] = s_std\n",
    "#     pd_means[count]=d_mean\n",
    "    #Trends in dp and sp: fit each patient's data with a linear regression and record the slope.\n",
    "    d_regr = linear_model.LinearRegression()\n",
    "    d_regr.fit(p_df.bmi_date.reshape(-1, 1), p_df.bmi.reshape(-1, 1))\n",
    "    b=d_regr.coef_.item(0)\n",
    "    ps_trends[count]=b\n",
    "\n",
    "x_bmi = pd.DataFrame({'patient_id':unique_ids, \n",
    "                     'bmi_mean': ps_means,'bmi_std': ps_std})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bmi_mean</th>\n",
       "      <th>bmi_std</th>\n",
       "      <th>patient_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>43.443846</td>\n",
       "      <td>4.362163</td>\n",
       "      <td>50135262</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>40.104062</td>\n",
       "      <td>56.286141</td>\n",
       "      <td>50135361</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>29.091786</td>\n",
       "      <td>26.354793</td>\n",
       "      <td>50135369</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>26.887687</td>\n",
       "      <td>2.139820</td>\n",
       "      <td>50135375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>33.648269</td>\n",
       "      <td>5.109400</td>\n",
       "      <td>50135425</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    bmi_mean    bmi_std  patient_id\n",
       "0  43.443846   4.362163    50135262\n",
       "1  40.104062  56.286141    50135361\n",
       "2  29.091786  26.354793    50135369\n",
       "3  26.887687   2.139820    50135375\n",
       "4  33.648269   5.109400    50135425"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_bmi = x_bmi.fillna(value=0)\n",
    "x_bmi.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BP: \n",
    "Blood pressure measurements. Includes the variables:\n",
    "1. \"SYSTOLIC\" (integer)\n",
    "2. \"DIASTOLIC\" (integer)\n",
    "3. \"Measure_date\" (M/DD/YY)\n",
    "\n",
    "The Systolic and Diastolic variables are used in the \"X\" dataset by taking a mean over all of the patients' values and recording one systolic pressure measurement and one diastolic pressure measurement per patient. We also included BPS_trend and BPD_trend variables, which is the slope of a linear regression model fit to the BP pressures over time. However, the maximum value for the trends was still very close to 0-- about 10^-13. Thus, we will have a general, mean measurement describing each patient, and will remove the trend values, since each patient's either stays constant or does not show a signficant increasing or decreasing trend.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "patient_id     0\n",
       "systolic       0\n",
       "diastolic      0\n",
       "bp_date       26\n",
       "dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "###\n",
    "#   BP\n",
    "###\n",
    "bp = pd.read_csv(data_path+\"FONNESBECK_BP.csv\", parse_dates=['Measure_date'], infer_datetime_format=True)\n",
    "bp.head()\n",
    "\n",
    "bp_clean = (bp\n",
    "            .rename(columns={\"RUID\": \"patient_id\", \n",
    "                             \"SYSTOLIC\": \"systolic\",\n",
    "                             \"DIASTOLIC\": \"diastolic\", \n",
    "                             \"Measure_date\": \"bp_date\"}))\n",
    "bp_clean['bp_date'] = pd.to_datetime(bp_clean.bp_date, errors='coerce')\n",
    "\n",
    "# only missing dates, may not need to address\n",
    "bp_clean.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>patient_id</th>\n",
       "      <th>systolic</th>\n",
       "      <th>diastolic</th>\n",
       "      <th>bp_date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>50135262</td>\n",
       "      <td>150</td>\n",
       "      <td>80</td>\n",
       "      <td>2005-01-09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>50135262</td>\n",
       "      <td>124</td>\n",
       "      <td>75</td>\n",
       "      <td>2011-02-19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>50135262</td>\n",
       "      <td>150</td>\n",
       "      <td>62</td>\n",
       "      <td>2011-02-19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>50135262</td>\n",
       "      <td>125</td>\n",
       "      <td>67</td>\n",
       "      <td>2011-02-19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>50135262</td>\n",
       "      <td>145</td>\n",
       "      <td>63</td>\n",
       "      <td>2011-02-19</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   patient_id  systolic  diastolic    bp_date\n",
       "0    50135262       150         80 2005-01-09\n",
       "1    50135262       124         75 2011-02-19\n",
       "2    50135262       150         62 2011-02-19\n",
       "3    50135262       125         67 2011-02-19\n",
       "4    50135262       145         63 2011-02-19"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bp_clean = bp_clean.sort_values('patient_id')\n",
    "bp_clean=bp_clean.reset_index(drop=True)\n",
    "\n",
    "bp_clean.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/geenaildefonso/anaconda/envs/bios8366/lib/python3.6/site-packages/ipykernel_launcher.py:20: FutureWarning: reshape is deprecated and will raise in a subsequent release. Please use .values.reshape(...) instead\n"
     ]
    }
   ],
   "source": [
    "from sklearn import datasets, linear_model\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "unique_ids = bp_clean.patient_id.unique()\n",
    "ps_means = list(range(len(unique_ids)))\n",
    "pd_means = list(range(len(unique_ids)))\n",
    "ps_trends = list(range(len(unique_ids)))\n",
    "pd_trends = list(range(len(unique_ids)))\n",
    "for p, count in zip(unique_ids, range(len(unique_ids))):\n",
    "#make a subsetted dataframe of just that ID\n",
    "    p_df = bp_clean[bp_clean.patient_id == p]\n",
    "    p_df=p_df.reset_index(drop=True)\n",
    "    #for each measurement in that list:\n",
    "    s_mean=p_df.systolic.mean()\n",
    "    d_mean=p_df.diastolic.mean()\n",
    "    ps_means[count]=s_mean\n",
    "    pd_means[count]=d_mean\n",
    "    #Trends in dp and sp: fit each patient's data with a linear regression and record the slope.\n",
    "    d_regr = linear_model.LinearRegression()\n",
    "    d_regr.fit(p_df.bp_date.reshape(-1, 1), p_df.diastolic.reshape(-1, 1))\n",
    "    b=d_regr.coef_.item(0)\n",
    "    pd_trends[count]=b\n",
    "\n",
    "x_bp = pd.DataFrame({'patient_id':unique_ids, \n",
    "                     'ps_mean': ps_means, 'pd_mean': pd_means,\n",
    "                     'ps_trend':ps_trends, 'pd_trend':pd_trends})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>patient_id</th>\n",
       "      <th>pd_mean</th>\n",
       "      <th>pd_trend</th>\n",
       "      <th>ps_mean</th>\n",
       "      <th>ps_trend</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>50135262</td>\n",
       "      <td>64.086464</td>\n",
       "      <td>-6.671398e-18</td>\n",
       "      <td>141.160834</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>50135361</td>\n",
       "      <td>59.877885</td>\n",
       "      <td>1.522614e-17</td>\n",
       "      <td>112.785374</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>50135369</td>\n",
       "      <td>70.011200</td>\n",
       "      <td>-1.273555e-17</td>\n",
       "      <td>115.893943</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>50135375</td>\n",
       "      <td>67.844574</td>\n",
       "      <td>-6.963159e-17</td>\n",
       "      <td>118.336822</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>50135425</td>\n",
       "      <td>56.765079</td>\n",
       "      <td>-8.611786e-17</td>\n",
       "      <td>128.038095</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   patient_id    pd_mean      pd_trend     ps_mean  ps_trend\n",
       "0    50135262  64.086464 -6.671398e-18  141.160834         0\n",
       "1    50135361  59.877885  1.522614e-17  112.785374         1\n",
       "2    50135369  70.011200 -1.273555e-17  115.893943         2\n",
       "3    50135375  67.844574 -6.963159e-17  118.336822         3\n",
       "4    50135425  56.765079 -8.611786e-17  128.038095         4"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_bp.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As mentioned above, the largest pd_trend value is about 10^-13. This was investigated for one patient below, showing that even though each blood pressure measurement varied, it was not in a significant direction. Thus, we decided to include the variance instead of the trend (slope of the linear regression)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>patient_id</th>\n",
       "      <th>systolic</th>\n",
       "      <th>diastolic</th>\n",
       "      <th>bp_date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>50135262</td>\n",
       "      <td>150</td>\n",
       "      <td>80</td>\n",
       "      <td>2005-01-09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>50135262</td>\n",
       "      <td>124</td>\n",
       "      <td>75</td>\n",
       "      <td>2011-02-19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>50135262</td>\n",
       "      <td>150</td>\n",
       "      <td>62</td>\n",
       "      <td>2011-02-19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>50135262</td>\n",
       "      <td>125</td>\n",
       "      <td>67</td>\n",
       "      <td>2011-02-19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>50135262</td>\n",
       "      <td>145</td>\n",
       "      <td>63</td>\n",
       "      <td>2011-02-19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>50135262</td>\n",
       "      <td>135</td>\n",
       "      <td>114</td>\n",
       "      <td>2011-02-19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>50135262</td>\n",
       "      <td>125</td>\n",
       "      <td>62</td>\n",
       "      <td>2011-02-19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>50135262</td>\n",
       "      <td>150</td>\n",
       "      <td>67</td>\n",
       "      <td>2011-02-19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>50135262</td>\n",
       "      <td>145</td>\n",
       "      <td>75</td>\n",
       "      <td>2011-02-19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>50135262</td>\n",
       "      <td>135</td>\n",
       "      <td>55</td>\n",
       "      <td>2011-02-19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>50135262</td>\n",
       "      <td>118</td>\n",
       "      <td>56</td>\n",
       "      <td>2011-02-19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>50135262</td>\n",
       "      <td>118</td>\n",
       "      <td>45</td>\n",
       "      <td>2011-02-19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>50135262</td>\n",
       "      <td>145</td>\n",
       "      <td>67</td>\n",
       "      <td>2011-02-19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>50135262</td>\n",
       "      <td>145</td>\n",
       "      <td>45</td>\n",
       "      <td>2011-02-19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>50135262</td>\n",
       "      <td>152</td>\n",
       "      <td>62</td>\n",
       "      <td>2011-02-19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>50135262</td>\n",
       "      <td>135</td>\n",
       "      <td>58</td>\n",
       "      <td>2011-02-19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>50135262</td>\n",
       "      <td>143</td>\n",
       "      <td>57</td>\n",
       "      <td>2011-02-19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>50135262</td>\n",
       "      <td>143</td>\n",
       "      <td>63</td>\n",
       "      <td>2011-02-19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>50135262</td>\n",
       "      <td>125</td>\n",
       "      <td>56</td>\n",
       "      <td>2011-02-19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>50135262</td>\n",
       "      <td>140</td>\n",
       "      <td>58</td>\n",
       "      <td>2011-02-19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>50135262</td>\n",
       "      <td>150</td>\n",
       "      <td>55</td>\n",
       "      <td>2011-02-19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>50135262</td>\n",
       "      <td>142</td>\n",
       "      <td>114</td>\n",
       "      <td>2011-02-19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>50135262</td>\n",
       "      <td>141</td>\n",
       "      <td>85</td>\n",
       "      <td>2011-02-19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>50135262</td>\n",
       "      <td>152</td>\n",
       "      <td>51</td>\n",
       "      <td>2011-02-19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>50135262</td>\n",
       "      <td>141</td>\n",
       "      <td>58</td>\n",
       "      <td>2011-02-19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>50135262</td>\n",
       "      <td>141</td>\n",
       "      <td>60</td>\n",
       "      <td>2011-02-19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>50135262</td>\n",
       "      <td>118</td>\n",
       "      <td>75</td>\n",
       "      <td>2011-02-19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>50135262</td>\n",
       "      <td>140</td>\n",
       "      <td>71</td>\n",
       "      <td>2011-02-19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>50135262</td>\n",
       "      <td>145</td>\n",
       "      <td>51</td>\n",
       "      <td>2011-02-19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>50135262</td>\n",
       "      <td>135</td>\n",
       "      <td>65</td>\n",
       "      <td>2011-02-19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3856</th>\n",
       "      <td>50135262</td>\n",
       "      <td>130</td>\n",
       "      <td>66</td>\n",
       "      <td>2011-02-13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3857</th>\n",
       "      <td>50135262</td>\n",
       "      <td>133</td>\n",
       "      <td>68</td>\n",
       "      <td>2011-02-13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3858</th>\n",
       "      <td>50135262</td>\n",
       "      <td>143</td>\n",
       "      <td>65</td>\n",
       "      <td>2011-02-13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3859</th>\n",
       "      <td>50135262</td>\n",
       "      <td>181</td>\n",
       "      <td>81</td>\n",
       "      <td>2011-02-13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3860</th>\n",
       "      <td>50135262</td>\n",
       "      <td>168</td>\n",
       "      <td>75</td>\n",
       "      <td>2011-02-13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3861</th>\n",
       "      <td>50135262</td>\n",
       "      <td>131</td>\n",
       "      <td>76</td>\n",
       "      <td>2011-02-13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3862</th>\n",
       "      <td>50135262</td>\n",
       "      <td>195</td>\n",
       "      <td>61</td>\n",
       "      <td>2011-02-13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3863</th>\n",
       "      <td>50135262</td>\n",
       "      <td>155</td>\n",
       "      <td>59</td>\n",
       "      <td>2011-02-13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3864</th>\n",
       "      <td>50135262</td>\n",
       "      <td>154</td>\n",
       "      <td>74</td>\n",
       "      <td>2011-02-13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3865</th>\n",
       "      <td>50135262</td>\n",
       "      <td>134</td>\n",
       "      <td>125</td>\n",
       "      <td>2011-02-13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3866</th>\n",
       "      <td>50135262</td>\n",
       "      <td>133</td>\n",
       "      <td>125</td>\n",
       "      <td>2011-02-13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3867</th>\n",
       "      <td>50135262</td>\n",
       "      <td>155</td>\n",
       "      <td>70</td>\n",
       "      <td>2011-02-13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3868</th>\n",
       "      <td>50135262</td>\n",
       "      <td>99</td>\n",
       "      <td>68</td>\n",
       "      <td>2011-02-13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3869</th>\n",
       "      <td>50135262</td>\n",
       "      <td>141</td>\n",
       "      <td>74</td>\n",
       "      <td>2011-02-13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3870</th>\n",
       "      <td>50135262</td>\n",
       "      <td>133</td>\n",
       "      <td>60</td>\n",
       "      <td>2011-02-13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3871</th>\n",
       "      <td>50135262</td>\n",
       "      <td>132</td>\n",
       "      <td>71</td>\n",
       "      <td>2011-02-13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3872</th>\n",
       "      <td>50135262</td>\n",
       "      <td>150</td>\n",
       "      <td>72</td>\n",
       "      <td>2011-02-13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3873</th>\n",
       "      <td>50135262</td>\n",
       "      <td>130</td>\n",
       "      <td>123</td>\n",
       "      <td>2011-02-13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3874</th>\n",
       "      <td>50135262</td>\n",
       "      <td>129</td>\n",
       "      <td>70</td>\n",
       "      <td>2011-02-13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3875</th>\n",
       "      <td>50135262</td>\n",
       "      <td>131</td>\n",
       "      <td>77</td>\n",
       "      <td>2011-02-13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3876</th>\n",
       "      <td>50135262</td>\n",
       "      <td>132</td>\n",
       "      <td>62</td>\n",
       "      <td>2011-02-13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3877</th>\n",
       "      <td>50135262</td>\n",
       "      <td>134</td>\n",
       "      <td>65</td>\n",
       "      <td>2011-02-13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3878</th>\n",
       "      <td>50135262</td>\n",
       "      <td>134</td>\n",
       "      <td>70</td>\n",
       "      <td>2011-02-13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3879</th>\n",
       "      <td>50135262</td>\n",
       "      <td>131</td>\n",
       "      <td>61</td>\n",
       "      <td>2011-02-13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3880</th>\n",
       "      <td>50135262</td>\n",
       "      <td>134</td>\n",
       "      <td>66</td>\n",
       "      <td>2011-02-13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3881</th>\n",
       "      <td>50135262</td>\n",
       "      <td>154</td>\n",
       "      <td>59</td>\n",
       "      <td>2011-02-13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3882</th>\n",
       "      <td>50135262</td>\n",
       "      <td>144</td>\n",
       "      <td>74</td>\n",
       "      <td>2011-02-13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3883</th>\n",
       "      <td>50135262</td>\n",
       "      <td>85</td>\n",
       "      <td>95</td>\n",
       "      <td>2011-02-13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3884</th>\n",
       "      <td>50135262</td>\n",
       "      <td>132</td>\n",
       "      <td>95</td>\n",
       "      <td>2011-02-13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3885</th>\n",
       "      <td>50135262</td>\n",
       "      <td>133</td>\n",
       "      <td>77</td>\n",
       "      <td>2011-02-13</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3886 rows Ã— 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      patient_id  systolic  diastolic    bp_date\n",
       "0       50135262       150         80 2005-01-09\n",
       "1       50135262       124         75 2011-02-19\n",
       "2       50135262       150         62 2011-02-19\n",
       "3       50135262       125         67 2011-02-19\n",
       "4       50135262       145         63 2011-02-19\n",
       "5       50135262       135        114 2011-02-19\n",
       "6       50135262       125         62 2011-02-19\n",
       "7       50135262       150         67 2011-02-19\n",
       "8       50135262       145         75 2011-02-19\n",
       "9       50135262       135         55 2011-02-19\n",
       "10      50135262       118         56 2011-02-19\n",
       "11      50135262       118         45 2011-02-19\n",
       "12      50135262       145         67 2011-02-19\n",
       "13      50135262       145         45 2011-02-19\n",
       "14      50135262       152         62 2011-02-19\n",
       "15      50135262       135         58 2011-02-19\n",
       "16      50135262       143         57 2011-02-19\n",
       "17      50135262       143         63 2011-02-19\n",
       "18      50135262       125         56 2011-02-19\n",
       "19      50135262       140         58 2011-02-19\n",
       "20      50135262       150         55 2011-02-19\n",
       "21      50135262       142        114 2011-02-19\n",
       "22      50135262       141         85 2011-02-19\n",
       "23      50135262       152         51 2011-02-19\n",
       "24      50135262       141         58 2011-02-19\n",
       "25      50135262       141         60 2011-02-19\n",
       "26      50135262       118         75 2011-02-19\n",
       "27      50135262       140         71 2011-02-19\n",
       "28      50135262       145         51 2011-02-19\n",
       "29      50135262       135         65 2011-02-19\n",
       "...          ...       ...        ...        ...\n",
       "3856    50135262       130         66 2011-02-13\n",
       "3857    50135262       133         68 2011-02-13\n",
       "3858    50135262       143         65 2011-02-13\n",
       "3859    50135262       181         81 2011-02-13\n",
       "3860    50135262       168         75 2011-02-13\n",
       "3861    50135262       131         76 2011-02-13\n",
       "3862    50135262       195         61 2011-02-13\n",
       "3863    50135262       155         59 2011-02-13\n",
       "3864    50135262       154         74 2011-02-13\n",
       "3865    50135262       134        125 2011-02-13\n",
       "3866    50135262       133        125 2011-02-13\n",
       "3867    50135262       155         70 2011-02-13\n",
       "3868    50135262        99         68 2011-02-13\n",
       "3869    50135262       141         74 2011-02-13\n",
       "3870    50135262       133         60 2011-02-13\n",
       "3871    50135262       132         71 2011-02-13\n",
       "3872    50135262       150         72 2011-02-13\n",
       "3873    50135262       130        123 2011-02-13\n",
       "3874    50135262       129         70 2011-02-13\n",
       "3875    50135262       131         77 2011-02-13\n",
       "3876    50135262       132         62 2011-02-13\n",
       "3877    50135262       134         65 2011-02-13\n",
       "3878    50135262       134         70 2011-02-13\n",
       "3879    50135262       131         61 2011-02-13\n",
       "3880    50135262       134         66 2011-02-13\n",
       "3881    50135262       154         59 2011-02-13\n",
       "3882    50135262       144         74 2011-02-13\n",
       "3883    50135262        85         95 2011-02-13\n",
       "3884    50135262       132         95 2011-02-13\n",
       "3885    50135262       133         77 2011-02-13\n",
       "\n",
       "[3886 rows x 4 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bp_clean.loc[bp_clean.patient_id == 50135262]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import statsmodels.formula.api as smf\n",
    "from sklearn import datasets, linear_model\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "unique_ids = bp_clean.patient_id.unique()\n",
    "ps_means = list(range(len(unique_ids)))\n",
    "pd_means = list(range(len(unique_ids)))\n",
    "ps_variance = list(range(len(unique_ids)))\n",
    "pd_variance = list(range(len(unique_ids)))\n",
    "for p, count in zip(unique_ids, range(len(unique_ids))):\n",
    "#make a subsetted dataframe of just that ID\n",
    "    p_df = bp_clean[bp_clean.patient_id == p]\n",
    "    p_df=p_df.reset_index(drop=True)\n",
    "    #for each measurement in that list:\n",
    "    s_mean=p_df.systolic.mean()\n",
    "    d_mean=p_df.diastolic.mean()\n",
    "    ps_means[count]=s_mean\n",
    "    pd_means[count]=d_mean\n",
    "    pd_variance[count]=p_df.diastolic.std()\n",
    "    ps_variance[count]=p_df.systolic.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "bp_full_clean = pd.DataFrame({'patient_id':unique_ids, \n",
    "                     'ps_mean': ps_means, 'pd_mean': pd_means,\n",
    "                     'ps_std':ps_variance, 'pd_std':pd_variance})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>patient_id</th>\n",
       "      <th>pd_mean</th>\n",
       "      <th>pd_std</th>\n",
       "      <th>ps_mean</th>\n",
       "      <th>ps_std</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>50135262</td>\n",
       "      <td>64.086464</td>\n",
       "      <td>13.579633</td>\n",
       "      <td>141.160834</td>\n",
       "      <td>20.377205</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>50135361</td>\n",
       "      <td>59.877885</td>\n",
       "      <td>12.678492</td>\n",
       "      <td>112.785374</td>\n",
       "      <td>18.694088</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>50135369</td>\n",
       "      <td>70.011200</td>\n",
       "      <td>11.986641</td>\n",
       "      <td>115.893943</td>\n",
       "      <td>17.587347</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>50135375</td>\n",
       "      <td>67.844574</td>\n",
       "      <td>12.547771</td>\n",
       "      <td>118.336822</td>\n",
       "      <td>21.254275</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>50135425</td>\n",
       "      <td>56.765079</td>\n",
       "      <td>9.300600</td>\n",
       "      <td>128.038095</td>\n",
       "      <td>16.444496</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   patient_id    pd_mean     pd_std     ps_mean     ps_std\n",
       "0    50135262  64.086464  13.579633  141.160834  20.377205\n",
       "1    50135361  59.877885  12.678492  112.785374  18.694088\n",
       "2    50135369  70.011200  11.986641  115.893943  17.587347\n",
       "3    50135375  67.844574  12.547771  118.336822  21.254275\n",
       "4    50135425  56.765079   9.300600  128.038095  16.444496"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_bp = bp_full_clean.fillna(value=0)\n",
    "x_bp.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MED: \n",
    "Medications information, including dose and duration.\n",
    "Includes the variables:\n",
    "1. \"Entry_Date\" (date M/DD/YY)\t\n",
    "2. \"Drug_Name\" (common drug name, string)\t\n",
    "3. \"DRUG_FORM\" (if drug comes in multiple forms, this describes which form is given. E.g. nebulizer versus inhaler for albuterol)\t\n",
    "4. \"DRUG_STRENGTH\" (mL, or NA)\n",
    "5. \"Route\" (Route of drug administration; e.g. IV, FLUSH, PO)\n",
    "6. \"Dose_Amt\" (Amount of drug, variable units; g, ML/HR, units)\n",
    "7. \"Drug_Freq\" (number of times given/how the drug is given; e.g. twice daily, once, Q1H PRN)\n",
    "8. \"Duration\" (length of time drug is given; e.g. months, days, etc)\n",
    "\n",
    "Cleaning of the MED dataset: From this dataset, we used Entry_date to include the data in our larger \"X\" data set. We included Drug_Name and dose amount, combined to be one variable. No other information from this dataset was used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "patient_id                0\n",
       "drug_entry_date        1110\n",
       "drug_name               201\n",
       "drug_form          10178627\n",
       "drug_strength       4950659\n",
       "drug_route          4431974\n",
       "drug_dose           8842506\n",
       "drug_freq           4702238\n",
       "drug_duration      12626046\n",
       "dtype: int64"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "###\n",
    "#   MED\n",
    "###\n",
    "med = pd.read_csv(data_path+\"FONNESBECK_MED.csv\", parse_dates=['Entry_Date'], infer_datetime_format=True)\n",
    "med.head()\n",
    "\n",
    "med_clean = (med\n",
    "             .rename(columns={\"RUID\": \"patient_id\", \n",
    "                              \"Entry_Date\": \"drug_entry_date\",\n",
    "                              \"Drug_Name\": \"drug_name\", \n",
    "                              \"DRUG_FORM\": \"drug_form\",\n",
    "                              \"DRUG_STRENGTH\": \"drug_strength\",\n",
    "                              \"Route\": \"drug_route\",\n",
    "                              \"Dose_Amt\": \"drug_dose\",\n",
    "                              \"Drug_Freq\": \"drug_freq\",\n",
    "                              \"Duration\": \"drug_duration\"}))\n",
    "med_clean.head()\n",
    "\n",
    "# lots of missing data in this table\n",
    "# many cols likely uninformative; drug_name might be most useful\n",
    "med_clean.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is so much missing data in this data set that we think we won't be able to get anything mesningful from including it in the model, so it is left out."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CPT: \n",
    "Procedure codes. Variables include:\n",
    "1. \"CPT_code\" (integer in most cases to describe categorical data)\n",
    "2. \"Event_date\" (M/DD/YY)\n",
    "\n",
    "This data is not included. Like the medicine data above, it has a lot of missing data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "patient_id        0\n",
       "cpt_code          0\n",
       "cpt_event_date    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "###\n",
    "#   CPT\n",
    "###\n",
    "cpt = pd.read_csv(data_path+\"FONNESBECK_CPT.csv\", parse_dates=['Event_date'], infer_datetime_format=True)\n",
    "cpt.head()\n",
    "\n",
    "cpt_clean = (cpt\n",
    "             .rename(columns={\"RUID\": \"patient_id\", \n",
    "                              \"CPT_Code\": \"cpt_code\",\n",
    "                              \"Event_date\": \"cpt_event_date\"}))\n",
    "cpt_clean.head()\n",
    "\n",
    "# no missing data\n",
    "cpt_clean.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### EGFR: \n",
    "Estimated Glomerular Filtration Rate measurements, used to screen for kidney damage. Obtained from a creatine lab. Includes the variables:\n",
    "1. \"EGFR\" (continuous data)\n",
    "2. \"egfr_date\" (date M/DD/YY)\n",
    "\n",
    "Again, we included this in the X dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>patient_id</th>\n",
       "      <th>egfr</th>\n",
       "      <th>egfr_date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>50135262</td>\n",
       "      <td>123.68000</td>\n",
       "      <td>2007-02-08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>50135262</td>\n",
       "      <td>123.67783</td>\n",
       "      <td>2007-02-08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>50135262</td>\n",
       "      <td>76.40173</td>\n",
       "      <td>2011-02-11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>50135262</td>\n",
       "      <td>76.40000</td>\n",
       "      <td>2011-02-11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>50135262</td>\n",
       "      <td>78.64000</td>\n",
       "      <td>2011-02-12</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   patient_id       egfr  egfr_date\n",
       "0    50135262  123.68000 2007-02-08\n",
       "1    50135262  123.67783 2007-02-08\n",
       "2    50135262   76.40173 2011-02-11\n",
       "3    50135262   76.40000 2011-02-11\n",
       "4    50135262   78.64000 2011-02-12"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "###\n",
    "#   EGFR\n",
    "###\n",
    "egfr = pd.read_csv(data_path+\"FONNESBECK_EGFR.csv\", parse_dates=['egfr_date'], infer_datetime_format=True)\n",
    "egfr.head()\n",
    "\n",
    "egfr_clean = (egfr.rename(columns={\"RUID\": \"patient_id\", \"EGFR\": \"egfr\"}))\n",
    "egfr_clean.head()\n",
    "\n",
    "# no missing data\n",
    "egfr_clean.isnull().sum()\n",
    "df_egfr = egfr_clean[['patient_id', 'egfr', 'egfr_date']]\n",
    "df_egfr.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/geenaildefonso/anaconda/envs/bios8366/lib/python3.6/site-packages/ipykernel_launcher.py:15: FutureWarning: reshape is deprecated and will raise in a subsequent release. Please use .values.reshape(...) instead\n",
      "  from ipykernel import kernelapp as app\n"
     ]
    }
   ],
   "source": [
    "unique_ids = df_egfr.patient_id.unique()\n",
    "ps_means = list(range(len(unique_ids)))\n",
    "ps_std = list(range(len(unique_ids)))\n",
    "ps_trends = list(range(len(unique_ids)))\n",
    "for p, count in zip(unique_ids, range(len(unique_ids))):\n",
    "#make a subsetted dataframe of just that ID\n",
    "    p_df = df_egfr[df_egfr.patient_id == p]\n",
    "    p_df=p_df.reset_index(drop=True)\n",
    "    #for each measurement in that list:\n",
    "    s_mean=p_df.egfr.mean()\n",
    "    s_std=p_df.egfr.std()\n",
    "    ps_means[count]=s_mean\n",
    "    ps_std[count] = s_std\n",
    "    d_regr = linear_model.LinearRegression()\n",
    "    d_regr.fit(p_df.egfr_date.reshape(-1, 1), p_df.egfr.reshape(-1, 1))\n",
    "    b=d_regr.coef_.item(0)\n",
    "    ps_trends[count]=b\n",
    "\n",
    "x_egfr = pd.DataFrame({'patient_id':unique_ids, \n",
    "                     'egfr_mean': ps_means,'egfr_std': ps_std})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>egfr_mean</th>\n",
       "      <th>egfr_std</th>\n",
       "      <th>patient_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>87.336092</td>\n",
       "      <td>24.538705</td>\n",
       "      <td>50135262</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>51.882929</td>\n",
       "      <td>18.630883</td>\n",
       "      <td>50135361</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>84.715450</td>\n",
       "      <td>14.981761</td>\n",
       "      <td>50135369</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>35.632098</td>\n",
       "      <td>19.640734</td>\n",
       "      <td>50135375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>35.230333</td>\n",
       "      <td>32.324784</td>\n",
       "      <td>50135425</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   egfr_mean   egfr_std  patient_id\n",
       "0  87.336092  24.538705    50135262\n",
       "1  51.882929  18.630883    50135361\n",
       "2  84.715450  14.981761    50135369\n",
       "3  35.632098  19.640734    50135375\n",
       "4  35.230333  32.324784    50135425"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_egfr.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ICD9: \n",
    "Coding of diagnosed diseases and health problems. This is an international standard for classifying diseases, including nuanced classifications of a wide variety of signs, symptoms, abnormal findings, complaints, social circumstances, and external causes of injury or disease. \n",
    "\n",
    "1. \"ICD9_Code\" (code for each disease/health problem)\n",
    "2. \"Event_date\"\n",
    "\n",
    "This data is not included in our models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "patient_id         0\n",
       "icd9_code          1\n",
       "icd9_event_date    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "###\n",
    "#   ICD9\n",
    "###\n",
    "icd9 = pd.read_csv(data_path+\"FONNESBECK_ICD9.csv\", parse_dates=['Event_date'], infer_datetime_format=True)\n",
    "icd9.head()\n",
    "\n",
    "icd9_clean = (icd9\n",
    "              .rename(columns={\"RUID\": \"patient_id\", \n",
    "                               \"ICD9_Code\": \"icd9_code\",\n",
    "                               \"Event_date\": \"icd9_event_date\"}))\n",
    "icd9_clean.head()\n",
    "\n",
    "# no missing data\n",
    "icd9_clean.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LAB: \n",
    "lab results, including the variables:\n",
    "1. \"Lab_name\" (Abbreviated name of lab test)\n",
    "2. \"Lab_date\" (date)\n",
    "3. \"Lab_value\" (result of test; may be numerical or categorical, such as blood type)\n",
    "\n",
    "This data was not incorporated into our large dataset. This information is hard (and somewhat unneccessary) to add to our models; for example, we do not expect blood type to have an effect on rate of readmission. For this reason, the data was not investigated as much as the other datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "patient_id            0\n",
       "short_lab_name        4\n",
       "lab_date              0\n",
       "lab_value         18489\n",
       "dtype: int64"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "###\n",
    "#   LAB\n",
    "###\n",
    "lab = pd.read_csv(data_path+\"FONNESBECK_LAB.csv\", parse_dates=['Lab_date'], \n",
    "                  infer_datetime_format=True, quoting=csv.QUOTE_NONE, na_values=['>'])\n",
    "lab.head()\n",
    "\n",
    "lab_clean = (lab\n",
    "             .rename(columns={\"RUID\": \"patient_id\", \n",
    "                              \"Lab_name\": \"short_lab_name\",\n",
    "                              \"Lab_date\": \"lab_date\", \n",
    "                              \"Lab_value\": \"lab_value\"}))\n",
    "lab_clean.head()\n",
    "\n",
    "# decent number of missing lab values\n",
    "# may be able to impute missing values if same patient \n",
    "lab_clean.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Phenotype: \n",
    "Patient attributes, including sex, race, and dates of birth and death.\n",
    "Includes the variables: \n",
    "1. \"Sex\" (F or M) \n",
    "2. \"DOB\" (date of birth)\n",
    "3. \"DOD\" (date of death)\n",
    "4. \"Race\" (W = white, B = black, I= Indian, A = Asian, N = Native American, H = hispanic, U = unidentified). \n",
    "\n",
    "Cleaning of the Phenotype dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>patient_id</th>\n",
       "      <th>sex</th>\n",
       "      <th>DOB</th>\n",
       "      <th>race</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>50135262</td>\n",
       "      <td>0</td>\n",
       "      <td>1949-09-20</td>\n",
       "      <td>W</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>50135361</td>\n",
       "      <td>1</td>\n",
       "      <td>1932-02-15</td>\n",
       "      <td>W</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>50135369</td>\n",
       "      <td>1</td>\n",
       "      <td>1958-05-04</td>\n",
       "      <td>W</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>50135375</td>\n",
       "      <td>1</td>\n",
       "      <td>1943-05-01</td>\n",
       "      <td>B</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>50135425</td>\n",
       "      <td>0</td>\n",
       "      <td>1946-10-02</td>\n",
       "      <td>W</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   patient_id sex        DOB race\n",
       "0    50135262   0 1949-09-20    W\n",
       "1    50135361   1 1932-02-15    W\n",
       "2    50135369   1 1958-05-04    W\n",
       "3    50135375   1 1943-05-01    B\n",
       "4    50135425   0 1946-10-02    W"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "###\n",
    "#   PHENOTYPE\n",
    "###\n",
    "phenotype = pd.read_csv(data_path+\"FONNESBECK_phenotype.csv\", parse_dates=['DOB', \"DOD\"], infer_datetime_format=True)\n",
    "phenotype.head()\n",
    "\n",
    "phenotype_clean = (phenotype\n",
    "                .rename(columns={\"RUID\": \"patient_id\", \n",
    "                                 \"Sex\": \"sex\",\n",
    "                                 \"DOB\": \"DOB\", \n",
    "                                 \"DOD\": \"DOD\",\n",
    "                                 \"Race\": \"race\"})\n",
    "                .replace({'sex':  {'F': 0,'M': 1, 'U': 'NaN', '.': 'NaN', 'NA': 'NaN'}}))\n",
    "phenotype_clean.head()\n",
    "\n",
    "# lots of missing DOBs and sex\n",
    "phenotype_clean.isnull().sum()\n",
    "df_pheno = phenotype_clean[['patient_id','sex', 'DOB', 'race']]\n",
    "df_pheno.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating the X dataset for prediction: Variables of Interest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After all of the above is done, we have each cleaned and organized dataset, and the ADT data is arranged into a dataframe with patient ID, admission date, and discharge date. Thus, each patient ID may be repeated for multiple rows, depending on how often they were admitted, but each visit should only be recorded once in its own row. To make a large dataset with all of the information we want to include for modeling, we will add data from the other datasets using the dates in those data sets. We will parse the other data sets (for example, BMI), by date (Date_BMI). For each event in the BMI dataset, we found the matching patient by ID. We then found the correct column by comparing the date of the measurement (Date_BMI) to the Admission date and Discharge date in each row for that patient (i.e., adding the BMI measurement to the column where the patient ID matches and Admission_date $\\leq$ Date_BMI $\\leq$ Discharge_date.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "merge1 = pd.merge(x_bmi,x_bp, how='outer', on = 'patient_id')\n",
    "merge2 = pd.merge(x_egfr, df_pheno,how='outer', on = 'patient_id')\n",
    "merged = pd.merge(merge1, merge2, how = 'outer', on ='patient_id')\n",
    "merged['race'] = merged['race'].map({'U': 0, 'A':1, 'B': 2, 'H':3,'I': 4, 'N':5, 'W':6})\n",
    "merged = merged[['bmi_mean', 'bmi_std', 'patient_id', 'pd_mean', 'pd_std', 'ps_mean', 'ps_std',\n",
    "                  'egfr_mean', 'egfr_std', 'sex', 'race']] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bmi_mean</th>\n",
       "      <th>bmi_std</th>\n",
       "      <th>patient_id</th>\n",
       "      <th>pd_mean</th>\n",
       "      <th>pd_std</th>\n",
       "      <th>ps_mean</th>\n",
       "      <th>ps_std</th>\n",
       "      <th>egfr_mean</th>\n",
       "      <th>egfr_std</th>\n",
       "      <th>sex</th>\n",
       "      <th>race</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>43.443846</td>\n",
       "      <td>4.362163</td>\n",
       "      <td>50135262</td>\n",
       "      <td>64.086464</td>\n",
       "      <td>13.579633</td>\n",
       "      <td>141.160834</td>\n",
       "      <td>20.377205</td>\n",
       "      <td>87.336092</td>\n",
       "      <td>24.538705</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>40.104062</td>\n",
       "      <td>56.286141</td>\n",
       "      <td>50135361</td>\n",
       "      <td>59.877885</td>\n",
       "      <td>12.678492</td>\n",
       "      <td>112.785374</td>\n",
       "      <td>18.694088</td>\n",
       "      <td>51.882929</td>\n",
       "      <td>18.630883</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>29.091786</td>\n",
       "      <td>26.354793</td>\n",
       "      <td>50135369</td>\n",
       "      <td>70.011200</td>\n",
       "      <td>11.986641</td>\n",
       "      <td>115.893943</td>\n",
       "      <td>17.587347</td>\n",
       "      <td>84.715450</td>\n",
       "      <td>14.981761</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>26.887687</td>\n",
       "      <td>2.139820</td>\n",
       "      <td>50135375</td>\n",
       "      <td>67.844574</td>\n",
       "      <td>12.547771</td>\n",
       "      <td>118.336822</td>\n",
       "      <td>21.254275</td>\n",
       "      <td>35.632098</td>\n",
       "      <td>19.640734</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>33.648269</td>\n",
       "      <td>5.109400</td>\n",
       "      <td>50135425</td>\n",
       "      <td>56.765079</td>\n",
       "      <td>9.300600</td>\n",
       "      <td>128.038095</td>\n",
       "      <td>16.444496</td>\n",
       "      <td>35.230333</td>\n",
       "      <td>32.324784</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    bmi_mean    bmi_std  patient_id    pd_mean     pd_std     ps_mean  \\\n",
       "0  43.443846   4.362163    50135262  64.086464  13.579633  141.160834   \n",
       "1  40.104062  56.286141    50135361  59.877885  12.678492  112.785374   \n",
       "2  29.091786  26.354793    50135369  70.011200  11.986641  115.893943   \n",
       "3  26.887687   2.139820    50135375  67.844574  12.547771  118.336822   \n",
       "4  33.648269   5.109400    50135425  56.765079   9.300600  128.038095   \n",
       "\n",
       "      ps_std  egfr_mean   egfr_std sex  race  \n",
       "0  20.377205  87.336092  24.538705   0     6  \n",
       "1  18.694088  51.882929  18.630883   1     6  \n",
       "2  17.587347  84.715450  14.981761   1     6  \n",
       "3  21.254275  35.632098  19.640734   1     2  \n",
       "4  16.444496  35.230333  32.324784   0     6  "
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dealing with Missing Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The phenotype dataset had data on every patient (8000); however, many of the other datasets are missing data. Some of the columns may be missing data due to error, or missing because the patient didn't have a certain test/procedure done. We decided to use the mean of each variable to impute the missing data below. Our justification is that the measurements with missing data are generally assumed to be normal (BMI, blood pressure, and EGFR), and thus imputation with the mean of the available data is a reasonable guess (most probabilistic guess). It wouldn't make sense to exclude the data, because many patients are missing data (especially BMI data; that dataset is only a tenth of the full patient list). It also wouldn't make sense to impute 0 or some other subjectively chosen number, because in many cases the expected number is not known to us (EGFR?), and cannot be 0 (BMI, blood pressure). Thus, the data itself is used to impute the missing data; since the dataset is so large, we feel that this is a reasonable approach."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "bmi_mean       0\n",
       "bmi_std        0\n",
       "patient_id     0\n",
       "pd_mean        0\n",
       "pd_std         0\n",
       "ps_mean        0\n",
       "ps_std         0\n",
       "egfr_mean      0\n",
       "egfr_std       0\n",
       "sex           43\n",
       "race           0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "values = {'bmi_mean': merged.bmi_mean.mean(), 'bmi_std': merged.bmi_std.mean(), 'pd_mean': merged.pd_mean.mean(),\n",
    "         'pd_std':merged.pd_std.mean(), 'ps_std': merged.ps_std.mean(), 'ps_mean': merged.ps_mean.mean(), \n",
    "         'egfr_mean': merged.egfr_mean.mean(), 'egfr_std': merged.egfr_std.mean()}\n",
    "merged= merged.fillna(value = values)\n",
    "merged.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that there are still 43 missing datapoints; these are for the sex variable. Since we don't know if they were male, female, or neither, we can't make a guess more educated than chance... and for gender, chance is about 50%. Thus, we chose to impute datapoints by forward filling: using the value above as the imputed value, since the value above also has about 50% of being female or male (and if there are more females than males, or vice versa, this method will capture that rate). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "bmi_mean      0\n",
       "bmi_std       0\n",
       "patient_id    0\n",
       "pd_mean       0\n",
       "pd_std        0\n",
       "ps_mean       0\n",
       "ps_std        0\n",
       "egfr_mean     0\n",
       "egfr_std      0\n",
       "sex           0\n",
       "race          0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged = merged.fillna(0)\n",
    "merged.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged.to_csv(data_path+\"merged_data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_data = pd.read_csv(data_path + \"merged_data.csv\", index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bmi_mean</th>\n",
       "      <th>bmi_std</th>\n",
       "      <th>patient_id</th>\n",
       "      <th>pd_mean</th>\n",
       "      <th>pd_std</th>\n",
       "      <th>ps_mean</th>\n",
       "      <th>ps_std</th>\n",
       "      <th>egfr_mean</th>\n",
       "      <th>egfr_std</th>\n",
       "      <th>sex</th>\n",
       "      <th>race</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>43.443846</td>\n",
       "      <td>4.362163</td>\n",
       "      <td>50135262</td>\n",
       "      <td>64.086464</td>\n",
       "      <td>13.579633</td>\n",
       "      <td>141.160834</td>\n",
       "      <td>20.377205</td>\n",
       "      <td>87.336092</td>\n",
       "      <td>24.538705</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>40.104062</td>\n",
       "      <td>56.286141</td>\n",
       "      <td>50135361</td>\n",
       "      <td>59.877885</td>\n",
       "      <td>12.678492</td>\n",
       "      <td>112.785374</td>\n",
       "      <td>18.694088</td>\n",
       "      <td>51.882929</td>\n",
       "      <td>18.630883</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>29.091786</td>\n",
       "      <td>26.354793</td>\n",
       "      <td>50135369</td>\n",
       "      <td>70.011200</td>\n",
       "      <td>11.986641</td>\n",
       "      <td>115.893943</td>\n",
       "      <td>17.587347</td>\n",
       "      <td>84.715450</td>\n",
       "      <td>14.981761</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>26.887687</td>\n",
       "      <td>2.139820</td>\n",
       "      <td>50135375</td>\n",
       "      <td>67.844574</td>\n",
       "      <td>12.547771</td>\n",
       "      <td>118.336822</td>\n",
       "      <td>21.254275</td>\n",
       "      <td>35.632098</td>\n",
       "      <td>19.640734</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>33.648269</td>\n",
       "      <td>5.109400</td>\n",
       "      <td>50135425</td>\n",
       "      <td>56.765079</td>\n",
       "      <td>9.300600</td>\n",
       "      <td>128.038095</td>\n",
       "      <td>16.444496</td>\n",
       "      <td>35.230333</td>\n",
       "      <td>32.324784</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    bmi_mean    bmi_std  patient_id    pd_mean     pd_std     ps_mean  \\\n",
       "0  43.443846   4.362163    50135262  64.086464  13.579633  141.160834   \n",
       "1  40.104062  56.286141    50135361  59.877885  12.678492  112.785374   \n",
       "2  29.091786  26.354793    50135369  70.011200  11.986641  115.893943   \n",
       "3  26.887687   2.139820    50135375  67.844574  12.547771  118.336822   \n",
       "4  33.648269   5.109400    50135425  56.765079   9.300600  128.038095   \n",
       "\n",
       "      ps_std  egfr_mean   egfr_std  sex  race  \n",
       "0  20.377205  87.336092  24.538705  0.0     6  \n",
       "1  18.694088  51.882929  18.630883  1.0     6  \n",
       "2  17.587347  84.715450  14.981761  1.0     6  \n",
       "3  21.254275  35.632098  19.640734  1.0     2  \n",
       "4  16.444496  35.230333  32.324784  0.0     6  "
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_data = merged_data\n",
    "x_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing of X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is important to both scale the data (normalize) and use One Hot Encoding to implement categorical variables in our models (sex, race, etc). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "patient_id = x_data[['patient_id']]\n",
    "x_data = x_data[['bmi_mean', 'bmi_std','pd_mean', 'pd_std', 'ps_mean', 'ps_std',\n",
    "                  'egfr_mean', 'egfr_std']]\n",
    "\n",
    "from sklearn import preprocessing\n",
    "x_data = preprocessing.normalize(x_data, norm='l2')\n",
    "x_data.shape\n",
    "\n",
    "x_data_norm=pd.DataFrame({'bmi_mean':x_data[:,0], 'bmi_std':x_data[:,1], 'pd_mean':x_data[:,2], 'pd_std':x_data[:,3],\n",
    "                     'ps_mean':x_data[:,4], 'ps_std':x_data[:,5],'egfr_mean':x_data[:,6], 'egfr_std':x_data[:,7]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_data_norm.loc[:,'patient_id'] = patient_id\n",
    "# x_data.to_csv('x_data_norm.csv')\n",
    "x_data_norm.head()\n",
    "x_data_norm.to_csv(data_path+\"normed.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_data_norm =pd.read_csv(data_path+\"normed.csv\", index_col= \"Unnamed: 0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bmi_mean</th>\n",
       "      <th>bmi_std</th>\n",
       "      <th>egfr_mean</th>\n",
       "      <th>egfr_std</th>\n",
       "      <th>pd_mean</th>\n",
       "      <th>pd_std</th>\n",
       "      <th>ps_mean</th>\n",
       "      <th>ps_std</th>\n",
       "      <th>patient_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.232986</td>\n",
       "      <td>0.023394</td>\n",
       "      <td>0.468378</td>\n",
       "      <td>0.131599</td>\n",
       "      <td>0.343691</td>\n",
       "      <td>0.072827</td>\n",
       "      <td>0.757036</td>\n",
       "      <td>0.109282</td>\n",
       "      <td>50135262</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.255530</td>\n",
       "      <td>0.358638</td>\n",
       "      <td>0.330582</td>\n",
       "      <td>0.118710</td>\n",
       "      <td>0.381523</td>\n",
       "      <td>0.080783</td>\n",
       "      <td>0.718633</td>\n",
       "      <td>0.119113</td>\n",
       "      <td>50135361</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.174707</td>\n",
       "      <td>0.158271</td>\n",
       "      <td>0.508748</td>\n",
       "      <td>0.089971</td>\n",
       "      <td>0.420444</td>\n",
       "      <td>0.071984</td>\n",
       "      <td>0.695987</td>\n",
       "      <td>0.105619</td>\n",
       "      <td>50135369</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.182953</td>\n",
       "      <td>0.014560</td>\n",
       "      <td>0.242454</td>\n",
       "      <td>0.133643</td>\n",
       "      <td>0.461639</td>\n",
       "      <td>0.085380</td>\n",
       "      <td>0.805206</td>\n",
       "      <td>0.144622</td>\n",
       "      <td>50135375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.219884</td>\n",
       "      <td>0.033389</td>\n",
       "      <td>0.230223</td>\n",
       "      <td>0.211236</td>\n",
       "      <td>0.370948</td>\n",
       "      <td>0.060777</td>\n",
       "      <td>0.836701</td>\n",
       "      <td>0.107461</td>\n",
       "      <td>50135425</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   bmi_mean   bmi_std  egfr_mean  egfr_std   pd_mean    pd_std   ps_mean  \\\n",
       "0  0.232986  0.023394   0.468378  0.131599  0.343691  0.072827  0.757036   \n",
       "1  0.255530  0.358638   0.330582  0.118710  0.381523  0.080783  0.718633   \n",
       "2  0.174707  0.158271   0.508748  0.089971  0.420444  0.071984  0.695987   \n",
       "3  0.182953  0.014560   0.242454  0.133643  0.461639  0.085380  0.805206   \n",
       "4  0.219884  0.033389   0.230223  0.211236  0.370948  0.060777  0.836701   \n",
       "\n",
       "     ps_std  patient_id  \n",
       "0  0.109282    50135262  \n",
       "1  0.119113    50135361  \n",
       "2  0.105619    50135369  \n",
       "3  0.144622    50135375  \n",
       "4  0.107461    50135425  "
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_data_norm.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To use the categorical data (Race and sex), we must use one hot encoding. The sex data is already binary, so we can leave it alone. We have already converted the races into label encoders by hand: 0 = unidentified, 1 = Asian, etc. These are converted back to letter after encoding (each as its own feature). The data can then be merged with the continous data in the model to use for prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = pd.read_csv(data_path+\"merged_data.csv\", index_col = \"patient_id\")\n",
    "X.head()\n",
    "del X['Unnamed: 0']\n",
    "race_data = X\n",
    "enc = preprocessing.OneHotEncoder()\n",
    "race = enc.fit(race_data[[\"race\"]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8000, 7)"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "race = enc.transform(race_data[[\"race\"]]).toarray()\n",
    "race.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "race_x = pd.DataFrame(columns=[\"U\", \"A\", \"B\", \"H\", \"I\", \"N\", \"W\"], data=race)\n",
    "race_x.loc[:,'patient_id'] = patient_id\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>U</th>\n",
       "      <th>A</th>\n",
       "      <th>B</th>\n",
       "      <th>H</th>\n",
       "      <th>I</th>\n",
       "      <th>N</th>\n",
       "      <th>W</th>\n",
       "      <th>patient_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>50135262</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>50135361</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>50135369</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>50135375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>50135425</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     U    A    B    H    I    N    W  patient_id\n",
       "0  0.0  0.0  0.0  0.0  0.0  0.0  1.0    50135262\n",
       "1  0.0  0.0  0.0  0.0  0.0  0.0  1.0    50135361\n",
       "2  0.0  0.0  0.0  0.0  0.0  0.0  1.0    50135369\n",
       "3  0.0  0.0  1.0  0.0  0.0  0.0  0.0    50135375\n",
       "4  0.0  0.0  0.0  0.0  0.0  0.0  1.0    50135425"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "race_x.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we just need to merge the categorical and normalized continuous data back into one dataframe:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_data_final = pd.merge(x_data_norm, race_x, on = \"patient_id\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bmi_mean</th>\n",
       "      <th>bmi_std</th>\n",
       "      <th>egfr_mean</th>\n",
       "      <th>egfr_std</th>\n",
       "      <th>pd_mean</th>\n",
       "      <th>pd_std</th>\n",
       "      <th>ps_mean</th>\n",
       "      <th>ps_std</th>\n",
       "      <th>patient_id</th>\n",
       "      <th>U</th>\n",
       "      <th>A</th>\n",
       "      <th>B</th>\n",
       "      <th>H</th>\n",
       "      <th>I</th>\n",
       "      <th>N</th>\n",
       "      <th>W</th>\n",
       "      <th>sex</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.232986</td>\n",
       "      <td>0.023394</td>\n",
       "      <td>0.468378</td>\n",
       "      <td>0.131599</td>\n",
       "      <td>0.343691</td>\n",
       "      <td>0.072827</td>\n",
       "      <td>0.757036</td>\n",
       "      <td>0.109282</td>\n",
       "      <td>50135262</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.255530</td>\n",
       "      <td>0.358638</td>\n",
       "      <td>0.330582</td>\n",
       "      <td>0.118710</td>\n",
       "      <td>0.381523</td>\n",
       "      <td>0.080783</td>\n",
       "      <td>0.718633</td>\n",
       "      <td>0.119113</td>\n",
       "      <td>50135361</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.174707</td>\n",
       "      <td>0.158271</td>\n",
       "      <td>0.508748</td>\n",
       "      <td>0.089971</td>\n",
       "      <td>0.420444</td>\n",
       "      <td>0.071984</td>\n",
       "      <td>0.695987</td>\n",
       "      <td>0.105619</td>\n",
       "      <td>50135369</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.182953</td>\n",
       "      <td>0.014560</td>\n",
       "      <td>0.242454</td>\n",
       "      <td>0.133643</td>\n",
       "      <td>0.461639</td>\n",
       "      <td>0.085380</td>\n",
       "      <td>0.805206</td>\n",
       "      <td>0.144622</td>\n",
       "      <td>50135375</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.219884</td>\n",
       "      <td>0.033389</td>\n",
       "      <td>0.230223</td>\n",
       "      <td>0.211236</td>\n",
       "      <td>0.370948</td>\n",
       "      <td>0.060777</td>\n",
       "      <td>0.836701</td>\n",
       "      <td>0.107461</td>\n",
       "      <td>50135425</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   bmi_mean   bmi_std  egfr_mean  egfr_std   pd_mean    pd_std   ps_mean  \\\n",
       "0  0.232986  0.023394   0.468378  0.131599  0.343691  0.072827  0.757036   \n",
       "1  0.255530  0.358638   0.330582  0.118710  0.381523  0.080783  0.718633   \n",
       "2  0.174707  0.158271   0.508748  0.089971  0.420444  0.071984  0.695987   \n",
       "3  0.182953  0.014560   0.242454  0.133643  0.461639  0.085380  0.805206   \n",
       "4  0.219884  0.033389   0.230223  0.211236  0.370948  0.060777  0.836701   \n",
       "\n",
       "     ps_std  patient_id    U    A    B    H    I    N    W  sex  \n",
       "0  0.109282    50135262  0.0  0.0  0.0  0.0  0.0  0.0  1.0  0.0  \n",
       "1  0.119113    50135361  0.0  0.0  0.0  0.0  0.0  0.0  1.0  1.0  \n",
       "2  0.105619    50135369  0.0  0.0  0.0  0.0  0.0  0.0  1.0  1.0  \n",
       "3  0.144622    50135375  0.0  0.0  1.0  0.0  0.0  0.0  0.0  1.0  \n",
       "4  0.107461    50135425  0.0  0.0  0.0  0.0  0.0  0.0  1.0  0.0  "
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_data_final.to_csv(data_path+\"x_data_final.csv\")\n",
    "x_data_final.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating the Y variable dataset for prediction: Rate of Readmission"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We used the same cleaned and organized ABT dataset to create a \"Y\" dataset that will be used to check our predictions of readmissions within 30 days of discharge. For each patient, we ran a for loop through the rows. Each row has a different discharge date, and this date was compared to all of the other admission dates to see if any admission dates were within 30 days of the discharge. If there is such a date, the loop is broken, the patient received a \"1\" value for a \"readmitted\" variable, and the next patient is investigated. This will give us a binary variable corresponding to the patients that were readmitted within 30 days at least once at any time. When building our models, we can use this information to check the accuracy of our models and for cross-validation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the above merged dataframe, I can compare discharge dates and admission dates for each patient. I will write a loop below that looks patient by patient. For each patient, I will loop through the discharge dates and compare them to the admission dates. If any are within 30 days of discharge, I will break from the inner loop, give the patient a \"1\", and move to the next patient."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([50135262, 50135361, 50135369, ..., 53736411, 53736418, 53736423])"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged = pd.read_csv(data_path+\"x_data.csv\")\n",
    "x = df_adt\n",
    "unique_ids = merged.patient_id.unique()\n",
    "unique_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8000\n"
     ]
    }
   ],
   "source": [
    "patients_readmitted = np.zeros(len(unique_ids))\n",
    "print(len(unique_ids))\n",
    "for p, count in zip(unique_ids, range(len(unique_ids))):\n",
    "#for p in [50135262]:\n",
    "#make a subsetted dataframe of just that ID\n",
    "    p_df = x[x.patient_id == p]\n",
    "    p_df=p_df.reset_index(drop=True)\n",
    "    #for each discharge_date in that list:\n",
    "    for i in range(len(p_df)):\n",
    "    #compare the discharge date to all of the admission dates in list\n",
    "        discharge = p_df.loc[i][\"discharge_date\"]\n",
    "        for j in range(len(p_df)):\n",
    "            readmit = p_df.loc[j][\"admission_date\"]\n",
    "            if (readmit - discharge > pd.to_timedelta('0 days')) and (readmit - discharge < pd.to_timedelta('30 days')):\n",
    "                patients_readmitted[count]=patients_readmitted[count]+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "readmitted_true = np.zeros(len(unique_ids))\n",
    "for i in range(len(readmitted_true)):\n",
    "    if patients_readmitted[i] > 0:\n",
    "        readmitted_true[i] = 1 \n",
    "y = pd.DataFrame({'patient_id':unique_ids, 'readmission':patients_readmitted, 'readmitted_true': readmitted_true})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>patient_id</th>\n",
       "      <th>readmission</th>\n",
       "      <th>readmitted_true</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>50135262</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>50135361</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>50135369</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>50135375</td>\n",
       "      <td>10.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>50135425</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   patient_id  readmission  readmitted_true\n",
       "0    50135262          1.0              1.0\n",
       "1    50135361          7.0              1.0\n",
       "2    50135369          2.0              1.0\n",
       "3    50135375         10.0              1.0\n",
       "4    50135425          1.0              1.0"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.to_csv(data_path+\"y_data.csv\")\n",
    "y.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Y is now a dataframe that includes the number of times the patient has been readmitted within 30 days, and the patient ID. We plan to model whether or not a patient was readmitted within 30 days at all, but we also though we may be able to predict more information by modeling a discrete variable, rather than a binary (1/0) variable. We've included both values depending on which we choose to model in each approach."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Please View Other Notebooks Before Reading Conclusion!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusions "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The objective of this course project was to employ modeling tools introduced in this course to fit prediction models for patient readmission within 30 days of discharge using synthetic derivative data. In accomplishing this goal of building these predictive models, we chose to imploy a Decision Tree and Random Forest Classifiers, Logistic Regression, and Support Vector Machine. In summary below, we discuss the best model from each predictive model, and the overall best model for this patient readmission data. \n",
    "\n",
    "DTC/RFC:\n",
    "The DTC did an okay job at being able to predict the actual values per patient for probability of readmission within 30 days into the Vanderbilt Hospital. This classifier performed more accurately in being able to predict if a patient was note readmitted within 30 days, as opposed to being readmitted. This classifier deemed the top node of most important feature to be the egfr standard deviation, which came at a suprise to us. We intially thought that the bmi would have been the highest rank in feature importance, and after running the RFC, the highest feature was also the egfr standard deviation. This model did perform the best with an accuracy score of 77%. We both agreed that the RFC was the best choice in models, because it is suited well for this kind of data, starting at a specific point, and asking questions giving answers that lead to subsequent questions. This model is able to split the data that we have into smaller segments, and is able to predict based on the importance of each feature the probability of a patient being readmitted within 30 days into the Vanderbilt Hospital. \n",
    "\n",
    "Logistic Regression:\n",
    "The Logistic Regression was the second best model in being able to predict the readmission rates for patients. This type of modeling is good for being able to split data into classes, here with one class being True for readmission into the hospital within 30 days, and the other class beign False for readmission into the hospital within 30 days. Initially trying the default paramters for C being 1, this actually performed the best with the highest accuracy score of 74%. Tuning the parameters of the model did not seem to perform better, all of them averaged around 72% accuracy. Here as well, we utilized the feature importance from the RFC to use as a plotting estimator for the Logistic Regression. In splitting the data predictions using the systolic blood pressure standard deviation and egfr standard deviation, you can visualize the split for True and False values based on the data. This showed to have better precision in predicting that a patient was readmitted to be True, as opposed to the lesser in predicting that a patietn was not being readmitted within 30 days. \n",
    "\n",
    "SVM:\n",
    "Support vector machines are useful in this problem because they work well in high dimensional spaces, and we have multiple variables that we want to use to predict readmission. The best SVM was using an RBF kernel with gamma = 100 and C = 0. This had the best accuracy and precision, but a very low recall score due to high number of false negatives. Most of the patients are negative, so this bias makes sense. We do not believe we overfit the data. With the messiness of the data and the data imputation that we had to do, we think this suggests that the accuracy of the model without overfitting will not be able to reach 100%, and therefore 73% accuracy with high precision is pretty good."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*The dataset(s) used for the analyses described were obtained from Vanderbilt University Medical Centerâ€™s Synthetic Derivative which is supported by institutional funding and by the Vanderbilt CTSA grant ULTR000445 from NCATS/NIH*"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
